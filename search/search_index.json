{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"After-Effects \u00b6 An effortless post install script for Ubuntu Why \u00b6 Upgrading a Linux machine comes with lot of headache. Somethings might break, somethings might not work or you might just want to start fresh. Beauty of Linux is almost everything is scriptable. Re-installing is just a matter of putting your favorite distribution on USB, install and configuring it. If you do it often and over a fleet of machines, then its a pain. You can run a few scripts to automate it, but they are not so flexible. A package changed its name? PPA not available for the current release? You need to edit your script, test it and run it. How \u00b6 What if your script could be \"configured\"? Just add the package you want to install to your config file. No need to search through code to do it. Separating your preferences and package lists from the script frees you from writing the script every time a new release comes around. This project helps you do just that. Its a glorified script written in bash!. How to \u00b6 See Getting Started . Supported Distros \u00b6 I have not tested the script on following distros. Because they use ubuntu as their base, It should work fine. But no promises. Tip Please check Supported-Distros for complete list of supported distros. Features \u00b6 Screenshots \u00b6 Uptime \u00b6","title":"Introduction"},{"location":"#after-effects","text":"An effortless post install script for Ubuntu","title":"After-Effects"},{"location":"#why","text":"Upgrading a Linux machine comes with lot of headache. Somethings might break, somethings might not work or you might just want to start fresh. Beauty of Linux is almost everything is scriptable. Re-installing is just a matter of putting your favorite distribution on USB, install and configuring it. If you do it often and over a fleet of machines, then its a pain. You can run a few scripts to automate it, but they are not so flexible. A package changed its name? PPA not available for the current release? You need to edit your script, test it and run it.","title":"Why"},{"location":"#how","text":"What if your script could be \"configured\"? Just add the package you want to install to your config file. No need to search through code to do it. Separating your preferences and package lists from the script frees you from writing the script every time a new release comes around. This project helps you do just that. Its a glorified script written in bash!.","title":"How"},{"location":"#how-to","text":"See Getting Started .","title":"How to"},{"location":"#supported-distros","text":"I have not tested the script on following distros. Because they use ubuntu as their base, It should work fine. But no promises. Tip Please check Supported-Distros for complete list of supported distros.","title":"Supported Distros"},{"location":"#features","text":"","title":"Features"},{"location":"#screenshots","text":"","title":"Screenshots"},{"location":"#uptime","text":"","title":"Uptime"},{"location":"changelogs/","text":"Changelogs \u00b6 Version 5.5.0 \u00b6 Eoan Support Remove Kubernetes repo. (kubespray/kubeadm works better) Minikube is still supported via binary method. Option to fallback to non LTS releases --pre-release flag now supports Debian Bullseye Fix Gist URL not workin g( #17 ) Introduce --autopilot flag Introduce DEBUG modes(activated if DEBUG=1) Version 5.4.3 \u00b6 Fix repo keys and fix classic snap installs Version 5.4.1 \u00b6 Add disco support, start testing on eoan Version 5.4.0 \u00b6 Add support for installing snap packages {edge, stable and classic} Version 5.3.7 \u00b6 Add support for Duo Security for Unix repos Version 5.3.6 \u00b6 Add ROS repository Redirect URLs to version which passed all tests. Update docs Version 5.3.4 \u00b6 Update WineHQ keys. Add new wine HQ keys to repo cleanup Add new Spotify key to repo cleanup Add new warning msg function Remove repeated debug msgs Version 5.3.3 \u00b6 Add support for Linux Mint 19.1 Tessa Version 5.3.2 \u00b6 Promote Cosmic to stable, add initial support for disco (19.04) Version 5.3.1 \u00b6 Add preliminary support for Debian 10 Buster. Fixed typos in documentation. Removed old files, Display git tag message in releases. Version 5.3.0 \u00b6 Move configuration files from /api to /config Update Spotify Keys [Fixes Spotify repos] Fix a bug which prevented Insync repo being added Version 5.2.0 \u00b6 New Feature: Static binaries installation (kompose,docker-compose etc) All script tmp files are now created /tmp/ae/ Version 5.1.2 \u00b6 Fix get script URLS. Fix Kubernetes repo url & repos for Linux Mint Version 5.1.0 \u00b6 Specify YAML config via URL. You can use config YAMLs saved as gists. Version 5.0 \u00b6 Remove Pre and Post Hooks. Configuration can be now done using YAML file. Its easier & gives more flexibility Lot of improvements & bug fixes. Now tagged versions are released to GitHub releases. Consolidate test scripts. Drop Artful support. Add support for Elementary OS 5 - Juno & Mint 19 Tara. Version checks also use YAML files. ARM support for some repositories. (not all repos support ARM) Move .redirects data to netlify toml Groundwork to move to parser written in Go. YAML provides more configuration options. Individual repos & tasks can now be controlled via YAML file. Version 4.0 \u00b6 Pre and Post Hooks for scripts. Custom list of scripts can be run Before and after all the tasks. Add version checks, always run latest version Brand new documentation site Use mkdocs to generate documentation Automatically push & deploy to gh-pages Use Netlify to manage gh-pages site Check if script is in current directory, to avoid errors on hooks Improve log file format: Reduce clutter Bug fixes and typo fixes Simplify TS logging Remote configuration for stats and stats server Ability to blacklist a release Prepare & add skeleton for stats reporting Version 3.6 \u00b6 Add Option to install system wide python packages using pip Promote Bionic to stable and update code-names Update pre-release to cosmic, rename test script for pre release Remove unused dockerfiles Version 3.4 \u00b6 Delete cached and downloaded DEBs. (Can be changed with - k flag ) Remove Gnome Specific stuff from default list Remove PPAs incompatible with bionic Bionic is supported with --pre-release flag only with default list. Version 3.3 \u00b6 Add Signal Desktop repository Better way to handle EOL error messages Fix: Visual Studio Code GPG key not deleted while removing repos. Lint Readme Markdown Nuke Sub-modules Version 3.2 \u00b6 Allow Bionic test to fail on Travis. Only print logs in Travis if there is an error or a flag is passed. Switch to sub-modules for data directory List files have their own repo now. Zesty reaches EOL soon. Remove it. Use daily images for bionic Version 3.1 \u00b6 Added Support for Upcoming Ubuntu release bionic. Added an option to use repository for last stable release on bionic. Use Ubuntu Base 18.04 LTS (Bionic Beaver) daily build to build docker image. Allow Bionic tests to fail on Travis CI. Dockerfiles & tests for bionic. Inform in script if running on Upcoming release. Drop google-cloud-sdk from fix_repo_not_available. Use --pre-release if using beta/alpha Ubuntu release. Add Visual studio to repos instead of deb files Rename logging directory to after-effects Version 3.0 \u00b6 Add Confirmation dialog using whiptail for Actions like Adding PPA, Repositories, Installing Apps, and Deb files Provide an option via command line to bypass the confirmation dialog for ci and automated environments or when its too annoying If the simulate option is selected then Only calculate the upgrade but do not perform upgrade. Added improved Simulate options. Helpful when just want to change somethings and test scripts without really downloading and installing packages Simulate option is by default false and can be toggled by passing - s or --simulate while running the script via command line Do not Enable Canonical Partner repositories in Ubuntu derivatives as they are enabled in installer or are different than Ubuntu. This leaves Partner repositories as they were before Add Feature: Purge Unwanted Packages Improved logging . Redirecting errors and adding time-stamps works better. Travis CI and Docker Testing Version 2.0 \u00b6 Complete rewrite from scratch Improvements in logging and console output Reduced verbosity in terminal output Flexible with packages and deb files Reduced complex dependencies Easy to configure Add Simulate install option for installing deb files and apps. Easier to test scripts now . Version 1.0 \u00b6 Initial upload.","title":"Changelog"},{"location":"changelogs/#changelogs","text":"","title":"Changelogs"},{"location":"changelogs/#version-550","text":"Eoan Support Remove Kubernetes repo. (kubespray/kubeadm works better) Minikube is still supported via binary method. Option to fallback to non LTS releases --pre-release flag now supports Debian Bullseye Fix Gist URL not workin g( #17 ) Introduce --autopilot flag Introduce DEBUG modes(activated if DEBUG=1)","title":"Version 5.5.0"},{"location":"changelogs/#version-543","text":"Fix repo keys and fix classic snap installs","title":"Version 5.4.3"},{"location":"changelogs/#version-541","text":"Add disco support, start testing on eoan","title":"Version 5.4.1"},{"location":"changelogs/#version-540","text":"Add support for installing snap packages {edge, stable and classic}","title":"Version 5.4.0"},{"location":"changelogs/#version-537","text":"Add support for Duo Security for Unix repos","title":"Version 5.3.7"},{"location":"changelogs/#version-536","text":"Add ROS repository Redirect URLs to version which passed all tests. Update docs","title":"Version 5.3.6"},{"location":"changelogs/#version-534","text":"Update WineHQ keys. Add new wine HQ keys to repo cleanup Add new Spotify key to repo cleanup Add new warning msg function Remove repeated debug msgs","title":"Version 5.3.4"},{"location":"changelogs/#version-533","text":"Add support for Linux Mint 19.1 Tessa","title":"Version 5.3.3"},{"location":"changelogs/#version-532","text":"Promote Cosmic to stable, add initial support for disco (19.04)","title":"Version 5.3.2"},{"location":"changelogs/#version-531","text":"Add preliminary support for Debian 10 Buster. Fixed typos in documentation. Removed old files, Display git tag message in releases.","title":"Version 5.3.1"},{"location":"changelogs/#version-530","text":"Move configuration files from /api to /config Update Spotify Keys [Fixes Spotify repos] Fix a bug which prevented Insync repo being added","title":"Version 5.3.0"},{"location":"changelogs/#version-520","text":"New Feature: Static binaries installation (kompose,docker-compose etc) All script tmp files are now created /tmp/ae/","title":"Version 5.2.0"},{"location":"changelogs/#version-512","text":"Fix get script URLS. Fix Kubernetes repo url & repos for Linux Mint","title":"Version 5.1.2"},{"location":"changelogs/#version-510","text":"Specify YAML config via URL. You can use config YAMLs saved as gists.","title":"Version 5.1.0"},{"location":"changelogs/#version-50","text":"Remove Pre and Post Hooks. Configuration can be now done using YAML file. Its easier & gives more flexibility Lot of improvements & bug fixes. Now tagged versions are released to GitHub releases. Consolidate test scripts. Drop Artful support. Add support for Elementary OS 5 - Juno & Mint 19 Tara. Version checks also use YAML files. ARM support for some repositories. (not all repos support ARM) Move .redirects data to netlify toml Groundwork to move to parser written in Go. YAML provides more configuration options. Individual repos & tasks can now be controlled via YAML file.","title":"Version 5.0"},{"location":"changelogs/#version-40","text":"Pre and Post Hooks for scripts. Custom list of scripts can be run Before and after all the tasks. Add version checks, always run latest version Brand new documentation site Use mkdocs to generate documentation Automatically push & deploy to gh-pages Use Netlify to manage gh-pages site Check if script is in current directory, to avoid errors on hooks Improve log file format: Reduce clutter Bug fixes and typo fixes Simplify TS logging Remote configuration for stats and stats server Ability to blacklist a release Prepare & add skeleton for stats reporting","title":"Version 4.0"},{"location":"changelogs/#version-36","text":"Add Option to install system wide python packages using pip Promote Bionic to stable and update code-names Update pre-release to cosmic, rename test script for pre release Remove unused dockerfiles","title":"Version 3.6"},{"location":"changelogs/#version-34","text":"Delete cached and downloaded DEBs. (Can be changed with - k flag ) Remove Gnome Specific stuff from default list Remove PPAs incompatible with bionic Bionic is supported with --pre-release flag only with default list.","title":"Version 3.4"},{"location":"changelogs/#version-33","text":"Add Signal Desktop repository Better way to handle EOL error messages Fix: Visual Studio Code GPG key not deleted while removing repos. Lint Readme Markdown Nuke Sub-modules","title":"Version 3.3"},{"location":"changelogs/#version-32","text":"Allow Bionic test to fail on Travis. Only print logs in Travis if there is an error or a flag is passed. Switch to sub-modules for data directory List files have their own repo now. Zesty reaches EOL soon. Remove it. Use daily images for bionic","title":"Version 3.2"},{"location":"changelogs/#version-31","text":"Added Support for Upcoming Ubuntu release bionic. Added an option to use repository for last stable release on bionic. Use Ubuntu Base 18.04 LTS (Bionic Beaver) daily build to build docker image. Allow Bionic tests to fail on Travis CI. Dockerfiles & tests for bionic. Inform in script if running on Upcoming release. Drop google-cloud-sdk from fix_repo_not_available. Use --pre-release if using beta/alpha Ubuntu release. Add Visual studio to repos instead of deb files Rename logging directory to after-effects","title":"Version 3.1"},{"location":"changelogs/#version-30","text":"Add Confirmation dialog using whiptail for Actions like Adding PPA, Repositories, Installing Apps, and Deb files Provide an option via command line to bypass the confirmation dialog for ci and automated environments or when its too annoying If the simulate option is selected then Only calculate the upgrade but do not perform upgrade. Added improved Simulate options. Helpful when just want to change somethings and test scripts without really downloading and installing packages Simulate option is by default false and can be toggled by passing - s or --simulate while running the script via command line Do not Enable Canonical Partner repositories in Ubuntu derivatives as they are enabled in installer or are different than Ubuntu. This leaves Partner repositories as they were before Add Feature: Purge Unwanted Packages Improved logging . Redirecting errors and adding time-stamps works better. Travis CI and Docker Testing","title":"Version 3.0"},{"location":"changelogs/#version-20","text":"Complete rewrite from scratch Improvements in logging and console output Reduced verbosity in terminal output Flexible with packages and deb files Reduced complex dependencies Easy to configure Add Simulate install option for installing deb files and apps. Easier to test scripts now .","title":"Version 2.0"},{"location":"changelogs/#version-10","text":"Initial upload.","title":"Version 1.0"},{"location":"clioptions/","text":"Command line options \u00b6 Configuration type \u00b6 You have two options of configuring this script. Using .list files in data ./after-effects --lists Using YAML files [they can be local or remote] You can specify local config file to use with -C / --config-file option. To use remote config file see -R/--remote-yaml Simulating package installation \u00b6 Usage ./after-effects -s OR ./after-effects --simulate This flag/option applies to following tasks Installing apt packages. Installing Debian package archives (DEBs). Installing Python packages. Upgrading system packages. Purging unwanted packages. Following details should explain the behavior of this flag. Please do have a look at exceptions, as all tasks cannot be simulated. This option will simulate installing packages mentioned in the lists, using the apt-get in-built dry-run option apt - get install - s to simulate the installation of packages. Nothing will be downloaded except repository metadata (deb files if option is chosen). Packages will not be installed. This option can be used to check if the files in the lists are compatible/available in the repository. Installation of DEB files also behaves similarly. It uses dpkg - i --dry-run to simulate installation. Its a very good idea to simulate installation when you have reconfigured the apps and packages in the list to check what might be error prone. In case of DEB package files, they will be downloaded unlike apt-get package installs. Exceptions - Not everything can be simulated Simulate flag will not simulate adding Repositories or PPAs. If you want to revert the changes please use Reset Repositories option. PPAs and repositories will be added regardless of the flag. Python package installation cannot be simulated. (pip lacks support for it) The script will skip installing apt dependencies and python packages, if simulate option is used. it simulate option is used. APT package upgrades and apt repository metadata updates cannot be simulated. Only a list of packages upgrade-able will be listed in the log file in case of upgrades. Simulate flag will not simulate installing dependencies for adding or deleting repositories and PPAs. Please do not set CI=\"true\" and TRAVIS=\"true\" in environment variables as they are reserved for testing and CI. They do not abide by the rules mentioned above. Skip Version Checks \u00b6 Usage ./after-effects --no-version-check OR ./after-effects -N Script will warn you and exit if you are not running latest version of the script. You can skip that by using the above option. This will also disable reporting usage stats. Fix for latest Ubuntu releases \u00b6 Usage ./after-effects -f OR ./after-effects --fix This flag/option applies to following repositories Google Cloud SDK GCSFUSE InSync Docker Community Edition Wine HQ Usually it takes a while for additional Repositories (Docker, Google Cloud SDK etc) to add support for latest release of Ubuntu. However we can use the previous release for which packages are available. So, using packages built for previous release works fine most of the time. This is also good fix if you are running a alpha or beta release of Ubuntu. These options only work on Ubuntu or distros using ubuntu codenames and Linux Mint. By default this option is disabled. Use - f or --fix option to enable this. Repositories like Spotify and Google Chrome do not use code names in their repository URLs. So the above workaround is not necessary. Derivatives of Ubuntu will use the code name of Ubuntu on which they are based. For example Linux mint 18.2 Serena will use code name xenial as it is based on Ubuntu 16.04 Xenial Xerus This option applies only for the latest release mentioned in the variable code_name_latest_release . and will be ignored if the release is not latest. Fix fallback to LTS \u00b6 Usage ./after-effects --fix-mode-lts Use LTS as fallback. This flag should be used in conjunction with --fix Otherwise it will be ignored. Instead of using previous Ubuntu release this will use the Last LTS release. i.e if you are on disco and use this bionic repositories will be used. Please use this with caution as it may not work. Note for Pre-Release/ development version of Ubuntu/Debian If you are using a pre-release version of Ubuntu, you can use --pre-release flag to apply the above mentioned fix to pre-release version of Ubuntu. This flag can be used independent of --fix . If both are used together then both flags will be applied if the release is upcoming-release. If the release is stable, only --fix flag will be valid and --pre-release is ignored. This is how it works: If the repositories are not available for latest stable release as well, go back a release. Ex. If the pre-release is 18.04 and the repositories is not available for 17.10 as well, we use 17.04 repositories. Usually happens in first few days of development cycle of 18.04. Purge not required packages \u00b6 Usage ./after-effects -d OR ./after-effects --purge Usually Ubuntu comes with some pre-installed games, packages which you might not need. This option is a switch to used in purging these packages mentioned in the subsequent sections. Since it is possible that user might purge necessary packages like sudo or other core system components, these just acts like a barrier from accidentally doing so. Warning This flag MUST be passed, if you intend to purge packages from system. Otherwise you will receive an error. If you are using YML config file you MUST set purge_enabled : true under config.flags. See Example YAML file for more info. Delete log file \u00b6 Usage ./after-effects -l OR ./after-effects --delete-log Just a quick way to delete logs generated by this script. Flag priority If you pass - l in the beginning rest of the commands will be ignored, as the script exits after deleting the log! Keep downloaded DEB files \u00b6 Usage ./after-effects -k OR ./after-effects --keep-debs Keeps packages cached by APT and downloaded DEB packages. Default behavior is to clean apt cache and delete downloaded DEB packages. Python packages Python package installation does not honor this flag. Hide Remote/local YAML configuration data \u00b6 Usage . / after - effects --hide-config OR ``` console . / after - effects - H ``` Hides displaying YAML configuration data in the output. Prefer Local lists \u00b6 Usage ./after-effects -L OR ./after-effects --lists Using this option, you can chose to use the lists file which you have locally and not worry about YAML. It is advised that you switch to YAML though. Not all options are supported with lists. Use Custom Configuration file \u00b6 Usage ./after-effects --config-file <filename> OR ./after-effects -C <filename> You can prefer using custom configuration file you have stored locally [It should be available via local paths or network share. not via ftp or http]. Enabling this option will disable fetching remote configuration even if you have specified --remote-yaml Use Custom Version information file \u00b6 Script always checks if its running the latest version available. If not it throws an error and exits. If you wish to skip that, please use --no-version-check . This is always recommended over using a custom version information file. However it is possible to provide a custom version info file, a YAML file which holds version information. Usage ./after-effects --version-file <filename> OR ./after-effects -V <filename> Example version file is in config directory. All the fields are mandatory. Remote YAML configuration file \u00b6 Usage ./after-effects --remote-yaml <URL to YAML file> OR ./after-effects -R <URL to YAML file> You can specify YAML file to use. Script will fetch it and parse it. Please note that local Config file specified takes priority over - R . If both -C & -R are used, only local config file is considered. The file should be available without any soft of interactive logins. Warning If using gists, please provide raw gist URL. Do not report statistics \u00b6 Usage ./after-effects --no-stats OR ./after-effects -S Disables reporting statistics back to server. Following things are reported. (Nothing more than that) A UUID generated for each execution, (its random and is not persistent across runs), Last exit code. System Architecture (x64/x86/ARM/ARM64). Total execution time. Randomized hostname Distribution name (Ubuntu, Linux Mint etc.) Distribution code name (bionic, artful etc) Feature/Task selected. Flags used. Timezone and system language. Privacy Concerns? If you are freaking out, its a shell script !! You can literally look into it and check what's collected. Why if you ask? I mostly use it on a bunch of machines/VMs and would like to keep an eye on how it did. Data will be stored in AWS DynamoDB and Google Firebase Real-time Database. Data will not be shared with any third party. Period. Only me or my team members will have access to it. If you run a search query on google, it probably collects more data than me. API endpoints/PaaS/IaaS provider may log your IP addresses, but script does not and WILL not collect IP addresses(local or otehrwise). Script will not collect your full config file either. Just flags used (like simulate, fix etc) If you flood the reporting endpoints, you might get HTTP 429 errors as reporting endpoints have rate limits. Uni-Freiburg Mirror \u00b6 Warning Enabling this option will use mirrors from Uni-Freiburg if they are available. You may have to be within Uni-Freiburg network to access it. The mirror may not work or be up-to date with upstream. Use this option only if you are inside Uni-Freiburg network and know what versions/libs are hosted on the mirror. Uses mirrors from University of Freiburg . Only available for limited number of repositories. DO NOT use this option if you are not a faculty or student of Uni-Freiburg, as it may have un-intended side effects. Arguments: - u or --use-uf-mirror . Because I do not wish to waste bandwidth this option is not tested on Travis builds. Warning This script/github-repository/or this website is not affiliated in with University of Freiburg. Version \u00b6 Usage ./after-effect -v OR ./after-effects --version This will display version info. You do not have to be root to run this. For all the other tasks you need to be root or use sudo. Autopilot Mode \u00b6 Autopilot mode is designed to run the script in a non interactive mannaer. Please see Autopilot in tasks for more info. Help \u00b6 Displays this help option. \u279c ./after-effects --help A Post Installation Script for Ubuntu/Debian/Linux Mint Usage: after-effects [options] Non-Action options (can be run as non-root user) ------------------------------------------------- [-v --version] Display version info [-h --help] Display this help message Configuration Options ------------------------------------------------- [-C | --config-file] Local yaml config file [-L | --lists] Read Configuration from .list files in data folder. [-n | --name] Name of the configuration file to use as a query parameter when -R / --remote-yaml is used [-R | --remote-yaml] Use config yaml hosted somewhere else [-V | --version-file] Specify a local file from which version info will be read The following options are \"action\" options and these will make changes to your system depending on tasks chosen. ------------------------------------------------- [-d | --purge] Enable Purging packages [-f | --fix] Fix codenames for new releases [-p | --pre-release] Same as --fix but for beta/alpha releases [--fix-mode-lts] Similar to --fix but fallback to last LTS Should be used with --fix [-k | --keep-debs] Do not invoke apt-clean & do not delete downloaded deb packages [-l | --delete-log] Delete logfile (./log/after-effects.log) [-s | --simulate] Try not make changes to system and use --dry-run whenever possible. Plese read the documentation at http://ae.prasadt.com/clioptions to know its limits Not everything can be simulated. Other Options ------------------------------------------------- [-E | --skip-env-checks] Skip some env checks [-N --no-version-checks] Skip checking for latest version [-H --hide-config] Hide configuration table [-S | --no-stats] Do not report usage statistics [--use-uf-mirror | -u] Use University of Freiburg mirrors [-A --autopilot] Enables AUTOPILOT mode(No Prompts) GitHub & Documentation: * https://github.com/tprasadtp/ubuntu-post-install * https://ae.prasadt.com Contributions & Issues: ------------------------------------------------- * You are welcome to contribute * Feel free to create a PullRequest/Issue on Github. * If it helped go and star the repo -------------------------------------------------","title":"Options"},{"location":"clioptions/#command-line-options","text":"","title":"Command line options"},{"location":"clioptions/#configuration-type","text":"You have two options of configuring this script. Using .list files in data ./after-effects --lists Using YAML files [they can be local or remote] You can specify local config file to use with -C / --config-file option. To use remote config file see -R/--remote-yaml","title":"Configuration type"},{"location":"clioptions/#simulating-package-installation","text":"Usage ./after-effects -s OR ./after-effects --simulate This flag/option applies to following tasks Installing apt packages. Installing Debian package archives (DEBs). Installing Python packages. Upgrading system packages. Purging unwanted packages. Following details should explain the behavior of this flag. Please do have a look at exceptions, as all tasks cannot be simulated. This option will simulate installing packages mentioned in the lists, using the apt-get in-built dry-run option apt - get install - s to simulate the installation of packages. Nothing will be downloaded except repository metadata (deb files if option is chosen). Packages will not be installed. This option can be used to check if the files in the lists are compatible/available in the repository. Installation of DEB files also behaves similarly. It uses dpkg - i --dry-run to simulate installation. Its a very good idea to simulate installation when you have reconfigured the apps and packages in the list to check what might be error prone. In case of DEB package files, they will be downloaded unlike apt-get package installs. Exceptions - Not everything can be simulated Simulate flag will not simulate adding Repositories or PPAs. If you want to revert the changes please use Reset Repositories option. PPAs and repositories will be added regardless of the flag. Python package installation cannot be simulated. (pip lacks support for it) The script will skip installing apt dependencies and python packages, if simulate option is used. it simulate option is used. APT package upgrades and apt repository metadata updates cannot be simulated. Only a list of packages upgrade-able will be listed in the log file in case of upgrades. Simulate flag will not simulate installing dependencies for adding or deleting repositories and PPAs. Please do not set CI=\"true\" and TRAVIS=\"true\" in environment variables as they are reserved for testing and CI. They do not abide by the rules mentioned above.","title":"Simulating package installation"},{"location":"clioptions/#skip-version-checks","text":"Usage ./after-effects --no-version-check OR ./after-effects -N Script will warn you and exit if you are not running latest version of the script. You can skip that by using the above option. This will also disable reporting usage stats.","title":"Skip Version Checks"},{"location":"clioptions/#fix-for-latest-ubuntu-releases","text":"Usage ./after-effects -f OR ./after-effects --fix This flag/option applies to following repositories Google Cloud SDK GCSFUSE InSync Docker Community Edition Wine HQ Usually it takes a while for additional Repositories (Docker, Google Cloud SDK etc) to add support for latest release of Ubuntu. However we can use the previous release for which packages are available. So, using packages built for previous release works fine most of the time. This is also good fix if you are running a alpha or beta release of Ubuntu. These options only work on Ubuntu or distros using ubuntu codenames and Linux Mint. By default this option is disabled. Use - f or --fix option to enable this. Repositories like Spotify and Google Chrome do not use code names in their repository URLs. So the above workaround is not necessary. Derivatives of Ubuntu will use the code name of Ubuntu on which they are based. For example Linux mint 18.2 Serena will use code name xenial as it is based on Ubuntu 16.04 Xenial Xerus This option applies only for the latest release mentioned in the variable code_name_latest_release . and will be ignored if the release is not latest.","title":"Fix for latest Ubuntu releases"},{"location":"clioptions/#fix-fallback-to-lts","text":"Usage ./after-effects --fix-mode-lts Use LTS as fallback. This flag should be used in conjunction with --fix Otherwise it will be ignored. Instead of using previous Ubuntu release this will use the Last LTS release. i.e if you are on disco and use this bionic repositories will be used. Please use this with caution as it may not work. Note for Pre-Release/ development version of Ubuntu/Debian If you are using a pre-release version of Ubuntu, you can use --pre-release flag to apply the above mentioned fix to pre-release version of Ubuntu. This flag can be used independent of --fix . If both are used together then both flags will be applied if the release is upcoming-release. If the release is stable, only --fix flag will be valid and --pre-release is ignored. This is how it works: If the repositories are not available for latest stable release as well, go back a release. Ex. If the pre-release is 18.04 and the repositories is not available for 17.10 as well, we use 17.04 repositories. Usually happens in first few days of development cycle of 18.04.","title":"Fix fallback to LTS"},{"location":"clioptions/#purge-not-required-packages","text":"Usage ./after-effects -d OR ./after-effects --purge Usually Ubuntu comes with some pre-installed games, packages which you might not need. This option is a switch to used in purging these packages mentioned in the subsequent sections. Since it is possible that user might purge necessary packages like sudo or other core system components, these just acts like a barrier from accidentally doing so. Warning This flag MUST be passed, if you intend to purge packages from system. Otherwise you will receive an error. If you are using YML config file you MUST set purge_enabled : true under config.flags. See Example YAML file for more info.","title":"Purge not required packages"},{"location":"clioptions/#delete-log-file","text":"Usage ./after-effects -l OR ./after-effects --delete-log Just a quick way to delete logs generated by this script. Flag priority If you pass - l in the beginning rest of the commands will be ignored, as the script exits after deleting the log!","title":"Delete log file"},{"location":"clioptions/#keep-downloaded-deb-files","text":"Usage ./after-effects -k OR ./after-effects --keep-debs Keeps packages cached by APT and downloaded DEB packages. Default behavior is to clean apt cache and delete downloaded DEB packages. Python packages Python package installation does not honor this flag.","title":"Keep downloaded DEB files"},{"location":"clioptions/#hide-remotelocal-yaml-configuration-data","text":"Usage . / after - effects --hide-config OR ``` console . / after - effects - H ``` Hides displaying YAML configuration data in the output.","title":"Hide Remote/local YAML configuration data"},{"location":"clioptions/#prefer-local-lists","text":"Usage ./after-effects -L OR ./after-effects --lists Using this option, you can chose to use the lists file which you have locally and not worry about YAML. It is advised that you switch to YAML though. Not all options are supported with lists.","title":"Prefer Local lists"},{"location":"clioptions/#use-custom-configuration-file","text":"Usage ./after-effects --config-file <filename> OR ./after-effects -C <filename> You can prefer using custom configuration file you have stored locally [It should be available via local paths or network share. not via ftp or http]. Enabling this option will disable fetching remote configuration even if you have specified --remote-yaml","title":"Use Custom Configuration file"},{"location":"clioptions/#use-custom-version-information-file","text":"Script always checks if its running the latest version available. If not it throws an error and exits. If you wish to skip that, please use --no-version-check . This is always recommended over using a custom version information file. However it is possible to provide a custom version info file, a YAML file which holds version information. Usage ./after-effects --version-file <filename> OR ./after-effects -V <filename> Example version file is in config directory. All the fields are mandatory.","title":"Use Custom Version information file"},{"location":"clioptions/#remote-yaml-configuration-file","text":"Usage ./after-effects --remote-yaml <URL to YAML file> OR ./after-effects -R <URL to YAML file> You can specify YAML file to use. Script will fetch it and parse it. Please note that local Config file specified takes priority over - R . If both -C & -R are used, only local config file is considered. The file should be available without any soft of interactive logins. Warning If using gists, please provide raw gist URL.","title":"Remote YAML configuration file"},{"location":"clioptions/#do-not-report-statistics","text":"Usage ./after-effects --no-stats OR ./after-effects -S Disables reporting statistics back to server. Following things are reported. (Nothing more than that) A UUID generated for each execution, (its random and is not persistent across runs), Last exit code. System Architecture (x64/x86/ARM/ARM64). Total execution time. Randomized hostname Distribution name (Ubuntu, Linux Mint etc.) Distribution code name (bionic, artful etc) Feature/Task selected. Flags used. Timezone and system language. Privacy Concerns? If you are freaking out, its a shell script !! You can literally look into it and check what's collected. Why if you ask? I mostly use it on a bunch of machines/VMs and would like to keep an eye on how it did. Data will be stored in AWS DynamoDB and Google Firebase Real-time Database. Data will not be shared with any third party. Period. Only me or my team members will have access to it. If you run a search query on google, it probably collects more data than me. API endpoints/PaaS/IaaS provider may log your IP addresses, but script does not and WILL not collect IP addresses(local or otehrwise). Script will not collect your full config file either. Just flags used (like simulate, fix etc) If you flood the reporting endpoints, you might get HTTP 429 errors as reporting endpoints have rate limits.","title":"Do not report statistics"},{"location":"clioptions/#uni-freiburg-mirror","text":"Warning Enabling this option will use mirrors from Uni-Freiburg if they are available. You may have to be within Uni-Freiburg network to access it. The mirror may not work or be up-to date with upstream. Use this option only if you are inside Uni-Freiburg network and know what versions/libs are hosted on the mirror. Uses mirrors from University of Freiburg . Only available for limited number of repositories. DO NOT use this option if you are not a faculty or student of Uni-Freiburg, as it may have un-intended side effects. Arguments: - u or --use-uf-mirror . Because I do not wish to waste bandwidth this option is not tested on Travis builds. Warning This script/github-repository/or this website is not affiliated in with University of Freiburg.","title":"Uni-Freiburg Mirror"},{"location":"clioptions/#version","text":"Usage ./after-effect -v OR ./after-effects --version This will display version info. You do not have to be root to run this. For all the other tasks you need to be root or use sudo.","title":"Version"},{"location":"clioptions/#autopilot-mode","text":"Autopilot mode is designed to run the script in a non interactive mannaer. Please see Autopilot in tasks for more info.","title":"Autopilot Mode"},{"location":"clioptions/#help","text":"Displays this help option. \u279c ./after-effects --help A Post Installation Script for Ubuntu/Debian/Linux Mint Usage: after-effects [options] Non-Action options (can be run as non-root user) ------------------------------------------------- [-v --version] Display version info [-h --help] Display this help message Configuration Options ------------------------------------------------- [-C | --config-file] Local yaml config file [-L | --lists] Read Configuration from .list files in data folder. [-n | --name] Name of the configuration file to use as a query parameter when -R / --remote-yaml is used [-R | --remote-yaml] Use config yaml hosted somewhere else [-V | --version-file] Specify a local file from which version info will be read The following options are \"action\" options and these will make changes to your system depending on tasks chosen. ------------------------------------------------- [-d | --purge] Enable Purging packages [-f | --fix] Fix codenames for new releases [-p | --pre-release] Same as --fix but for beta/alpha releases [--fix-mode-lts] Similar to --fix but fallback to last LTS Should be used with --fix [-k | --keep-debs] Do not invoke apt-clean & do not delete downloaded deb packages [-l | --delete-log] Delete logfile (./log/after-effects.log) [-s | --simulate] Try not make changes to system and use --dry-run whenever possible. Plese read the documentation at http://ae.prasadt.com/clioptions to know its limits Not everything can be simulated. Other Options ------------------------------------------------- [-E | --skip-env-checks] Skip some env checks [-N --no-version-checks] Skip checking for latest version [-H --hide-config] Hide configuration table [-S | --no-stats] Do not report usage statistics [--use-uf-mirror | -u] Use University of Freiburg mirrors [-A --autopilot] Enables AUTOPILOT mode(No Prompts) GitHub & Documentation: * https://github.com/tprasadtp/ubuntu-post-install * https://ae.prasadt.com Contributions & Issues: ------------------------------------------------- * You are welcome to contribute * Feel free to create a PullRequest/Issue on Github. * If it helped go and star the repo -------------------------------------------------","title":"Help"},{"location":"configuration/","text":"Overview of Configuration files \u00b6 This Script is designed to be flexible. You have two options of configuring this script. list files directory / data & YAML configurations are in config . Configuration using lists \u00b6 These files contain list of apt packages which can be installed. Please see Installing APT packages for more information. File Contents administration Administration Tools like Synaptic development Used for development tasks eg: ruby external Packages from PPAs or External repositories. eg : Google Chrome, Spotify, Visual Studio Code, Google Cloud SDKs multimedia Tools to edit photos and videos, video players and editors. productivity Email, Chat, Office tools, Document converters etc. security Security related tools utilities Utilities and Tools Non package related lists (settings, deb files, delete packages list). The use and format is explained in individual sections. File Contents Used by function Link to section gsettings Various gsettings None Yet NA purge List of packages to be purged purge_not_required Link ppa List of ppas to be added add_ppas Link deb List of DEB files to be installed (csv) install_debs Link get.mlist Used by get-after-effects.sh to download required list files NA get-after-effects.sh pip2/pip3 Python packages (Installed System wide) _install_pip_packages Link Tip After you customize, might want to use simulate flag. sudo . / after - effects - s - L YAML File \u00b6 The script can fetch remote YAML data from given url. Use --remote-yaml URL If you want to use a local config file, use --config-file FILENAME It contains following details. If you specify a an option via command line and provide config file which has conflicting option, Config file takes precedence. Remote configuration is displayed as [ R - Config ] in the logs and on the screen. To hide it use --hide-config Check Sample YAML configuration file here. Using local file If you are testing, it might be a good idea to use a local file which holds this configuration data. In that case use - C < filename > option. After you customize, might want to use simulate flag. sudo . / after - effects - s - C config . yml - Y If both - C and --remote-yaml are used, local config file takes priority, and remote file is completely ignored. Autopilot mode \u00b6 Setting \"AUTOPILOT=true\" or --autopilot will run all the tasks specified in the YAML file, or if - L list option is used, then all tasks are executed. the order in which tasks are run is as follows. Update Upgrade Add Repositories Add PPAs [if supported] Install packages Install DEB packages Install Python2 Modules Install Python 3 Modules Purge unwanted Packages Install Snap packages Reserved Environmenat Variables \u00b6 Prefix AE_ is reserved along with TRAVIS_ as they are used for configuration and testing. Please do not set CI=\"true\" in your environment variables. they will alter how script honors --similate flag and --autopilot flag as they are reserved for testing on CI systems.","title":"Configuration"},{"location":"configuration/#overview-of-configuration-files","text":"This Script is designed to be flexible. You have two options of configuring this script. list files directory / data & YAML configurations are in config .","title":"Overview of Configuration files"},{"location":"configuration/#configuration-using-lists","text":"These files contain list of apt packages which can be installed. Please see Installing APT packages for more information. File Contents administration Administration Tools like Synaptic development Used for development tasks eg: ruby external Packages from PPAs or External repositories. eg : Google Chrome, Spotify, Visual Studio Code, Google Cloud SDKs multimedia Tools to edit photos and videos, video players and editors. productivity Email, Chat, Office tools, Document converters etc. security Security related tools utilities Utilities and Tools Non package related lists (settings, deb files, delete packages list). The use and format is explained in individual sections. File Contents Used by function Link to section gsettings Various gsettings None Yet NA purge List of packages to be purged purge_not_required Link ppa List of ppas to be added add_ppas Link deb List of DEB files to be installed (csv) install_debs Link get.mlist Used by get-after-effects.sh to download required list files NA get-after-effects.sh pip2/pip3 Python packages (Installed System wide) _install_pip_packages Link Tip After you customize, might want to use simulate flag. sudo . / after - effects - s - L","title":"Configuration using  lists"},{"location":"configuration/#yaml-file","text":"The script can fetch remote YAML data from given url. Use --remote-yaml URL If you want to use a local config file, use --config-file FILENAME It contains following details. If you specify a an option via command line and provide config file which has conflicting option, Config file takes precedence. Remote configuration is displayed as [ R - Config ] in the logs and on the screen. To hide it use --hide-config Check Sample YAML configuration file here. Using local file If you are testing, it might be a good idea to use a local file which holds this configuration data. In that case use - C < filename > option. After you customize, might want to use simulate flag. sudo . / after - effects - s - C config . yml - Y If both - C and --remote-yaml are used, local config file takes priority, and remote file is completely ignored.","title":"YAML File"},{"location":"configuration/#autopilot-mode","text":"Setting \"AUTOPILOT=true\" or --autopilot will run all the tasks specified in the YAML file, or if - L list option is used, then all tasks are executed. the order in which tasks are run is as follows. Update Upgrade Add Repositories Add PPAs [if supported] Install packages Install DEB packages Install Python2 Modules Install Python 3 Modules Purge unwanted Packages Install Snap packages","title":"Autopilot mode"},{"location":"configuration/#reserved-environmenat-variables","text":"Prefix AE_ is reserved along with TRAVIS_ as they are used for configuration and testing. Please do not set CI=\"true\" in your environment variables. they will alter how script honors --similate flag and --autopilot flag as they are reserved for testing on CI systems.","title":"Reserved Environmenat Variables"},{"location":"getting-started/","text":"How to use? \u00b6 Install Ubuntu \u00b6 Install (if you haven't already) your choice of Ubuntu/Derivative as you would( If you wish to automate that too, you can use preseed.cfg file) Step 1: Get the script \u00b6 Without Git \u00b6 Run this in Terminal wget -Nnv https://ae.prasadt.com/get -O - | bash URL redirects to file with last known good commit on GitHub. It is cached & proxies to GitHub at CDN level. If you are paranoid, use git. If you wish to use master branch pass --master or - m as an argument. Eg: wget - Nnv https : // ae . prasadt . com / get - O - | bash - s --master With Git \u00b6 If you already have git on your system, you can use, git clone https://github.com/tprasadtp/ubuntu-post-install.git && cd ubuntu-post-install If you already have cloned the repo, you can use git pull to get the latest changes. This will use master branch which may not be as stable as versioned releases. Step 2: Update the lists or config.yml to suit your needs \u00b6 Update the list or config files to suit your needs. Change PPAs, add or delete packages to list, tweak variables etc. Please see Configuration & Tasks for more details. Some example configs can be found here . Step 3: Run it \u00b6 Run the script as root . You will get an error if you do not run the script as root. Tip Before you run the script, make sure that its executable. sudo ./after-effects -C <your config.yml> To use lists sudo ./after-effects -L Note for using this script inside docker containers If you are running this in a docker container, you probably are root. Its possible that you might be missing sudo package. So In that case just run it as . / after - effects . Be warned! You probably are missing several dependencies of the script!","title":"Getting Started"},{"location":"getting-started/#how-to-use","text":"","title":"How to use?"},{"location":"getting-started/#install-ubuntu","text":"Install (if you haven't already) your choice of Ubuntu/Derivative as you would( If you wish to automate that too, you can use preseed.cfg file)","title":"Install Ubuntu"},{"location":"getting-started/#step-1-get-the-script","text":"","title":"Step 1: Get the script"},{"location":"getting-started/#without-git","text":"Run this in Terminal wget -Nnv https://ae.prasadt.com/get -O - | bash URL redirects to file with last known good commit on GitHub. It is cached & proxies to GitHub at CDN level. If you are paranoid, use git. If you wish to use master branch pass --master or - m as an argument. Eg: wget - Nnv https : // ae . prasadt . com / get - O - | bash - s --master","title":"Without Git"},{"location":"getting-started/#with-git","text":"If you already have git on your system, you can use, git clone https://github.com/tprasadtp/ubuntu-post-install.git && cd ubuntu-post-install If you already have cloned the repo, you can use git pull to get the latest changes. This will use master branch which may not be as stable as versioned releases.","title":"With Git"},{"location":"getting-started/#step-2-update-the-lists-or-configyml-to-suit-your-needs","text":"Update the list or config files to suit your needs. Change PPAs, add or delete packages to list, tweak variables etc. Please see Configuration & Tasks for more details. Some example configs can be found here .","title":"Step 2: Update the lists or config.yml to suit your needs"},{"location":"getting-started/#step-3-run-it","text":"Run the script as root . You will get an error if you do not run the script as root. Tip Before you run the script, make sure that its executable. sudo ./after-effects -C <your config.yml> To use lists sudo ./after-effects -L Note for using this script inside docker containers If you are running this in a docker container, you probably are root. Its possible that you might be missing sudo package. So In that case just run it as . / after - effects . Be warned! You probably are missing several dependencies of the script!","title":"Step 3: Run it"},{"location":"license/","text":"License \u00b6 This project is licensed under GPL v3. You should have received a copy of the license along with this software. External libraries and tools \u00b6 This project uses mkdocs for documentation and mkdocs-material theme.","title":"License"},{"location":"license/#license","text":"This project is licensed under GPL v3. You should have received a copy of the license along with this software.","title":"License"},{"location":"license/#external-libraries-and-tools","text":"This project uses mkdocs for documentation and mkdocs-material theme.","title":"External libraries and tools"},{"location":"logs/","text":"Logs \u00b6 Logs are written to a file < current - dir >/ logs / after - effects . log . Time-stamps in the logs may not be accurate because some commands buffer outputs. Sensitive Log files might contain sensitive information or personally identifying information. They are not uploaded anywhere.","title":"Logs"},{"location":"logs/#logs","text":"Logs are written to a file < current - dir >/ logs / after - effects . log . Time-stamps in the logs may not be accurate because some commands buffer outputs. Sensitive Log files might contain sensitive information or personally identifying information. They are not uploaded anywhere.","title":"Logs"},{"location":"privacy/","text":"Privacy Policy \u00b6 Privacy policy related to website is available here . Anonymous stats collection \u00b6 Info Your passwords, usernames, environment variables or anything sensitive is not collected. This feature is currently disabled The script after - effects collects anonymous usage statistics. The following might be collected. Randomized UUID generated per run. Last exit code. System Architecture (x64/x86/ARM/ARM64). Total execution time. Randomized hostname Distribution name (Ubuntu, Linux Mint etc.) Distribution code name (bionic, artful etc) Feature/Task selected. Flags used. Timezone and system language. Tip No personally identifiable information is collected or reported back. This feature can be disabled via --no-stats flag.","title":"Privacy Policy"},{"location":"privacy/#privacy-policy","text":"Privacy policy related to website is available here .","title":"Privacy Policy"},{"location":"privacy/#anonymous-stats-collection","text":"Info Your passwords, usernames, environment variables or anything sensitive is not collected. This feature is currently disabled The script after - effects collects anonymous usage statistics. The following might be collected. Randomized UUID generated per run. Last exit code. System Architecture (x64/x86/ARM/ARM64). Total execution time. Randomized hostname Distribution name (Ubuntu, Linux Mint etc.) Distribution code name (bionic, artful etc) Feature/Task selected. Flags used. Timezone and system language. Tip No personally identifiable information is collected or reported back. This feature can be disabled via --no-stats flag.","title":"Anonymous stats collection"},{"location":"tasks/","text":"What can it do? \u00b6 Add Repositories \u00b6 This task can add the following repositories. Name Key Docker docker Duo Security Unix duo Google Chrome & Google Earth google Google Cloud SDK googlecloud GCSFUSE gcsfuse Insync insync Mendeley desktop mendeley ROS ros Signal for desktop signal Skype skype Spotify Desktop spotify Visual Studio code vscode Wine HQ winehq Using --fix falg Please note that the above repositories are sometimes not updated for latest Ubuntu release and most certainly will not be available for upcoming release of Ubuntu(Alpha/Beta). It might take some time till the repositories are available for the latest release. Use -f or --fix command line option or --pre-release in case you are using a Development version of ubuntu to revert using latest available version of repositories (usually previous Ubuntu release or in case of Beta/Alpha latest stable release of ubuntu). For more info see command line options. Controlling which repository is added using config file You can set your YML file to decide which repository is added. Some repositories may no be supported on your architecture or distribution. Take a look at config.yml for example. If you omit a value, it defaults to false ALWAYS . Do note that if you are using lists default values are different, they are mentioned in below. Default Variables if using Lists #============================ Switches/ bools ================================ # Latest wine builds add_winehq_repo = false #Docker community edition add_docker_repo = true #Mendeley Desktop add_mendeley_repo = false #Spotify add_spotify_repo = true #InSync add_insync_repo = false #Google Cloud SDK add_googlecloud_repo = false add_gcsfuse_Repo = false #Signal add_signal_repo = false #Skype add_skype_repo = true #VS code add_vscode_repo = true #Google add_google_repo = true #ROS add_ros_repo = false # Define Data Directory data_dir = \"data\" ROS Releases & Ubuntu/Debian versions ROS releases only support certain Ubuntu/Debian distributions. Please use appropriate packages to install depending on your distro/version. You can find more info at ROS-Wiki Though Ubuntu derivatives might work, they are not supported. Canonical partner repositories \u00b6 Canonical partner repositories are not configured or enabled for derivatives of Ubuntu because thee might be some conflicts. Note on 32 bit & ARM Architecture Please note that Google Chrome doesn't support 32 bit architecture, please use Chromium. Signal, Skype, Mendeley and Visual studio code do not support 32 bit architecture. Some repositories are not available for ARM architecture. Add personal package archives (PPA) \u00b6 PPAs can be added using the configuration file in data directory . / data / ppa . list or in the YML file. Only one ppa entry per line (No comments or anything else anywhere in the file) in the format ppa:{author}/{ppa} for example ppa : mozillateam / firefox - next The file will be read and the PPAs will be added from the list. Logs will show entry in the format [ date and time ] [ PPA - Logs ] < log > Warning PPAs should be checked before they are added to the list. Sometimes PPAs listed in the file may not be available for all releases. Debian does not support PPAs. Install apt packages \u00b6 Packages can be installed by using configuration lists in the data directory. This works similar to ppas There are seven lists under key config.install.apt.[mentioned from 1-7] \u00b6 administration - Contains Administrative packages security - Contains Security related tools and packages productivity - Office tools, writing tools, LateX, document tools and other productivity tools, Email clients, browsers, IM clients etc. Example : LateX, TeXStudio, Libre office, pandoc empathy, Thunderbird multimedia - Multimedia tools like media players, audio converters and playes etc. development - IDEs [Spyder, Jetbeans etc], languages [go, python, ruby, rust, java etc], Containers [docker lxc rkt etc], Python libraries, compilers [gcc, clang] SDKs [AWS SDK, Google Cloud SDK, open-jdk, Tensor Flow], headers and libraries[ocl-icd-dev], Anything related to development and -dev or -devl packages. other - Everything which does not fit in the above categories. Themes, Tools, Utilities like htop etc. external - Any packages which are provided by ppas, or repositories not present in base [K/L/Ed/X]-Ubuntu distribution. There's a possibility that the repository might not be added or may be unavailable or offline. So Keeping the list separate from others packages minimizes errors if there are any. This classification is only for ease of use and need not be strictly followed. You can put 'vlc' package in 'security', it will still install fine. This classification helps while writing configs and editing them. Its advised to follow it if your configs tend to get to couple of hundreds of lines. Also YAML file should be a valid YAML & indented by 2 spaces. Special list - Purge list \u00b6 There is a special package list under key, config.purge or purge.list, which contains list of apt packages to be purged from the system. Make sure that all the packages in the lists are available for your release. Using - s command line option helps. Also check for the logs for any errors or conflicts. Install Debian package archives (.deb files) \u00b6 This will install deb files specified in the list deb . list or YAML config under config . install . debian_packages . Logs will show entry in the format [ < date and time > ] [ PKG ] < log > for dpkg actions and APT Logs will show entry in the format [ < date and time > ] [ APT ] < log > for actions performed by apt commands. ( apt - get install - f for missing packages) Simulate option will use --dry-run option in dpkg to Simulate DEB installation. Configuration file is a csv file without headers. first column corresponds to URL ans the second field the file name under which the file is saved. Each DEB file to be installed should have following entry. URL to the deb file which can be accessed using wget , Name of the deb file without any spaces or special chars except hyphen. For example to install Atom Editor the entry should look like below. https : // atom - installer . github . com / v1 . 21 . 1 / atom - amd64 . deb , ATOM - Editor . deb First part is the URL to the deb file separated by ',' name of the file. Note on file names in configuration Please note that deb file will be saved with the name mentioned in the file. (DEB file is named exactly as mentioned in the second field. So if you want them to be named with extension .deb include that in the second field and avoid illegal chars) Install Static binaries to /usr/local/bin \u00b6 This will install binaries bin . list or YAML config under config . install . binaries . Simulate option will download the package but not install it. Configuration file is a csv file without headers. first column corresponds to URL ans the second field the file name under which the file is saved. Each DEB file to be installed should have following entry. URL to the deb file which can be accessed using wget , Name of the deb file without any spaces or special chars except hyphen. For example, to install kubernetes compose, the entry should look like below. https : // github . com / kubernetes / kompose / releases / download / v1 . 19 . 0 / kompose - linux - amd64 , kompose First part is the URL to the binary file separated by ',' name of the binary. Note on file names in configuration Please note that file will be saved with the name mentioned in the file & can be executed as such. Install python packages (via pip) \u00b6 This will install system wide python packages using pip. There are two lists. pip . list and pip3 . list for python 2 and python 3 respectively. Alternatively you can specify in YAML config under config . install . python2 or config . install . python3 This task requires python - pip package is installed, If not , will be installed anyway. The list files follow similar configuration as package list files. One item per line. however you can specify version requirements as you would for requirements file. Simulate flag will skip installing packages, unless CI = true . Warning Don't mix Python 3 packages with Python 2 packages. Purge Unwanted Packages \u00b6 This will purge Unwanted packages from the system. The packages mentioned in the list purge.list or under config . purge in yaml will be purged The format of the purge.list is similar to that of packages, one packages per line of the file and no comments or anything else. Warning It is necessary to pass command line argument - d or --deboalt to run this task if you are using lists mode. With YML you can set the flag config . flags . purge_enabled : true in config and - d is not necessary. Reset repositories / Purge PPAs \u00b6 This will reset the repositories added by this script, and purge ppas added by this script in the list ppa.list or config yaml. This will NOT reset or remove repositories added by the DEB files. Simulate option has no effect on this action and ppa-purge WILL downgrade packages if necessary. Scope of this function This will NOT remove PPAs or repositories you have added manually or those added while installing DEB files. Installing Snap packages \u00b6 Script can install snap packages from snapstore. For example check the default config file. Warning List mode does not support installing snap packages. Its responsibility of the user to separate classic snaps, edge and normal snaps. You should specify the classic snaps under install . snaps . calssic , edge snaps under install . snaps . edge and normal snaps under install . snaps . normal in the yaml file. All In one \u00b6 This will perform Following actions. (In the following order) Update repository metadata Upgrade packages Add repositories Add PPAs in the list file Install Apps Install DEB files Install Python 2 modules Install Python 3 Modules Install Static binaries This option will honor --autopilot and --simulate options as individual tasks would do if used with YAML. Lists mode does not support for selecting individiual tasks. AUTOPILOT Mode \u00b6 Setting AUTOPILOT = true or passing --autopilot will will skip all UI prompts and confirmations and run ALL In One. Delete logs \u00b6 A log file is generated containing all the output generated by the apt and other commands and contain generic information and errors . This task will delete the log file after - effects . log . Log file is located in the directory logs in folder which you ran thin script. Sometimes errors might not be written to log file but displayed on screen and vice-versa. Please verify that everything went okay before deleting the logs.","title":"What can it do?"},{"location":"tasks/#what-can-it-do","text":"","title":"What can it do?"},{"location":"tasks/#add-repositories","text":"This task can add the following repositories. Name Key Docker docker Duo Security Unix duo Google Chrome & Google Earth google Google Cloud SDK googlecloud GCSFUSE gcsfuse Insync insync Mendeley desktop mendeley ROS ros Signal for desktop signal Skype skype Spotify Desktop spotify Visual Studio code vscode Wine HQ winehq Using --fix falg Please note that the above repositories are sometimes not updated for latest Ubuntu release and most certainly will not be available for upcoming release of Ubuntu(Alpha/Beta). It might take some time till the repositories are available for the latest release. Use -f or --fix command line option or --pre-release in case you are using a Development version of ubuntu to revert using latest available version of repositories (usually previous Ubuntu release or in case of Beta/Alpha latest stable release of ubuntu). For more info see command line options. Controlling which repository is added using config file You can set your YML file to decide which repository is added. Some repositories may no be supported on your architecture or distribution. Take a look at config.yml for example. If you omit a value, it defaults to false ALWAYS . Do note that if you are using lists default values are different, they are mentioned in below. Default Variables if using Lists #============================ Switches/ bools ================================ # Latest wine builds add_winehq_repo = false #Docker community edition add_docker_repo = true #Mendeley Desktop add_mendeley_repo = false #Spotify add_spotify_repo = true #InSync add_insync_repo = false #Google Cloud SDK add_googlecloud_repo = false add_gcsfuse_Repo = false #Signal add_signal_repo = false #Skype add_skype_repo = true #VS code add_vscode_repo = true #Google add_google_repo = true #ROS add_ros_repo = false # Define Data Directory data_dir = \"data\" ROS Releases & Ubuntu/Debian versions ROS releases only support certain Ubuntu/Debian distributions. Please use appropriate packages to install depending on your distro/version. You can find more info at ROS-Wiki Though Ubuntu derivatives might work, they are not supported.","title":"Add Repositories"},{"location":"tasks/#canonical-partner-repositories","text":"Canonical partner repositories are not configured or enabled for derivatives of Ubuntu because thee might be some conflicts. Note on 32 bit & ARM Architecture Please note that Google Chrome doesn't support 32 bit architecture, please use Chromium. Signal, Skype, Mendeley and Visual studio code do not support 32 bit architecture. Some repositories are not available for ARM architecture.","title":"Canonical partner repositories"},{"location":"tasks/#add-personal-package-archives-ppa","text":"PPAs can be added using the configuration file in data directory . / data / ppa . list or in the YML file. Only one ppa entry per line (No comments or anything else anywhere in the file) in the format ppa:{author}/{ppa} for example ppa : mozillateam / firefox - next The file will be read and the PPAs will be added from the list. Logs will show entry in the format [ date and time ] [ PPA - Logs ] < log > Warning PPAs should be checked before they are added to the list. Sometimes PPAs listed in the file may not be available for all releases. Debian does not support PPAs.","title":"Add personal package archives (PPA)"},{"location":"tasks/#install-apt-packages","text":"Packages can be installed by using configuration lists in the data directory. This works similar to ppas","title":"Install apt packages"},{"location":"tasks/#there-are-seven-lists-under-key-configinstallaptmentioned-from-1-7","text":"administration - Contains Administrative packages security - Contains Security related tools and packages productivity - Office tools, writing tools, LateX, document tools and other productivity tools, Email clients, browsers, IM clients etc. Example : LateX, TeXStudio, Libre office, pandoc empathy, Thunderbird multimedia - Multimedia tools like media players, audio converters and playes etc. development - IDEs [Spyder, Jetbeans etc], languages [go, python, ruby, rust, java etc], Containers [docker lxc rkt etc], Python libraries, compilers [gcc, clang] SDKs [AWS SDK, Google Cloud SDK, open-jdk, Tensor Flow], headers and libraries[ocl-icd-dev], Anything related to development and -dev or -devl packages. other - Everything which does not fit in the above categories. Themes, Tools, Utilities like htop etc. external - Any packages which are provided by ppas, or repositories not present in base [K/L/Ed/X]-Ubuntu distribution. There's a possibility that the repository might not be added or may be unavailable or offline. So Keeping the list separate from others packages minimizes errors if there are any. This classification is only for ease of use and need not be strictly followed. You can put 'vlc' package in 'security', it will still install fine. This classification helps while writing configs and editing them. Its advised to follow it if your configs tend to get to couple of hundreds of lines. Also YAML file should be a valid YAML & indented by 2 spaces.","title":"There are seven lists under key config.install.apt.[mentioned from 1-7]"},{"location":"tasks/#special-list-purge-list","text":"There is a special package list under key, config.purge or purge.list, which contains list of apt packages to be purged from the system. Make sure that all the packages in the lists are available for your release. Using - s command line option helps. Also check for the logs for any errors or conflicts.","title":"Special list - Purge list"},{"location":"tasks/#install-debian-package-archives-deb-files","text":"This will install deb files specified in the list deb . list or YAML config under config . install . debian_packages . Logs will show entry in the format [ < date and time > ] [ PKG ] < log > for dpkg actions and APT Logs will show entry in the format [ < date and time > ] [ APT ] < log > for actions performed by apt commands. ( apt - get install - f for missing packages) Simulate option will use --dry-run option in dpkg to Simulate DEB installation. Configuration file is a csv file without headers. first column corresponds to URL ans the second field the file name under which the file is saved. Each DEB file to be installed should have following entry. URL to the deb file which can be accessed using wget , Name of the deb file without any spaces or special chars except hyphen. For example to install Atom Editor the entry should look like below. https : // atom - installer . github . com / v1 . 21 . 1 / atom - amd64 . deb , ATOM - Editor . deb First part is the URL to the deb file separated by ',' name of the file. Note on file names in configuration Please note that deb file will be saved with the name mentioned in the file. (DEB file is named exactly as mentioned in the second field. So if you want them to be named with extension .deb include that in the second field and avoid illegal chars)","title":"Install Debian package archives (.deb files)"},{"location":"tasks/#install-static-binaries-to-usrlocalbin","text":"This will install binaries bin . list or YAML config under config . install . binaries . Simulate option will download the package but not install it. Configuration file is a csv file without headers. first column corresponds to URL ans the second field the file name under which the file is saved. Each DEB file to be installed should have following entry. URL to the deb file which can be accessed using wget , Name of the deb file without any spaces or special chars except hyphen. For example, to install kubernetes compose, the entry should look like below. https : // github . com / kubernetes / kompose / releases / download / v1 . 19 . 0 / kompose - linux - amd64 , kompose First part is the URL to the binary file separated by ',' name of the binary. Note on file names in configuration Please note that file will be saved with the name mentioned in the file & can be executed as such.","title":"Install Static binaries to /usr/local/bin"},{"location":"tasks/#install-python-packages-via-pip","text":"This will install system wide python packages using pip. There are two lists. pip . list and pip3 . list for python 2 and python 3 respectively. Alternatively you can specify in YAML config under config . install . python2 or config . install . python3 This task requires python - pip package is installed, If not , will be installed anyway. The list files follow similar configuration as package list files. One item per line. however you can specify version requirements as you would for requirements file. Simulate flag will skip installing packages, unless CI = true . Warning Don't mix Python 3 packages with Python 2 packages.","title":"Install python packages (via pip)"},{"location":"tasks/#purge-unwanted-packages","text":"This will purge Unwanted packages from the system. The packages mentioned in the list purge.list or under config . purge in yaml will be purged The format of the purge.list is similar to that of packages, one packages per line of the file and no comments or anything else. Warning It is necessary to pass command line argument - d or --deboalt to run this task if you are using lists mode. With YML you can set the flag config . flags . purge_enabled : true in config and - d is not necessary.","title":"Purge Unwanted Packages"},{"location":"tasks/#reset-repositories-purge-ppas","text":"This will reset the repositories added by this script, and purge ppas added by this script in the list ppa.list or config yaml. This will NOT reset or remove repositories added by the DEB files. Simulate option has no effect on this action and ppa-purge WILL downgrade packages if necessary. Scope of this function This will NOT remove PPAs or repositories you have added manually or those added while installing DEB files.","title":"Reset repositories / Purge PPAs"},{"location":"tasks/#installing-snap-packages","text":"Script can install snap packages from snapstore. For example check the default config file. Warning List mode does not support installing snap packages. Its responsibility of the user to separate classic snaps, edge and normal snaps. You should specify the classic snaps under install . snaps . calssic , edge snaps under install . snaps . edge and normal snaps under install . snaps . normal in the yaml file.","title":"Installing Snap packages"},{"location":"tasks/#all-in-one","text":"This will perform Following actions. (In the following order) Update repository metadata Upgrade packages Add repositories Add PPAs in the list file Install Apps Install DEB files Install Python 2 modules Install Python 3 Modules Install Static binaries This option will honor --autopilot and --simulate options as individual tasks would do if used with YAML. Lists mode does not support for selecting individiual tasks.","title":"All In one"},{"location":"tasks/#autopilot-mode","text":"Setting AUTOPILOT = true or passing --autopilot will will skip all UI prompts and confirmations and run ALL In One.","title":"AUTOPILOT Mode"},{"location":"tasks/#delete-logs","text":"A log file is generated containing all the output generated by the apt and other commands and contain generic information and errors . This task will delete the log file after - effects . log . Log file is located in the directory logs in folder which you ran thin script. Sometimes errors might not be written to log file but displayed on screen and vice-versa. Please verify that everything went okay before deleting the logs.","title":"Delete logs"},{"location":"testing/","text":"CI and Testing \u00b6 Test Scripts Test Scripts assume that you are running on Travis. So They might fail if some environment variables are not set. Please see, Travis environment variables . Following Tests are done on Travis-CI. shellcheck every executable bash script, Test on all supported Ubuntu and Debian distros Test scripts on all supported Ubuntu and Debian releases. Info Test on arm only use YAML config not lists Additionally script is also tested on ARM64 on bionic Dockerfiles used for building the image are in / dockerfiles directory, they use official Ubuntu base images with script dependencies. Test scripts are located in / tests directory. Since its a time consuming process only simulated install is done on CI. Linux mint and Elementary are not tested in containers. It is possible that there might be some errors specific to your setup. Please report if so. It is Strongly advised to try simulate mode first before proceeding with actual installation. Warning Never set environment variable CI = true or TRAVIS = true , unless you are running in a CI environment or are sure of its effects.","title":"Testing"},{"location":"testing/#ci-and-testing","text":"Test Scripts Test Scripts assume that you are running on Travis. So They might fail if some environment variables are not set. Please see, Travis environment variables . Following Tests are done on Travis-CI. shellcheck every executable bash script, Test on all supported Ubuntu and Debian distros Test scripts on all supported Ubuntu and Debian releases. Info Test on arm only use YAML config not lists Additionally script is also tested on ARM64 on bionic Dockerfiles used for building the image are in / dockerfiles directory, they use official Ubuntu base images with script dependencies. Test scripts are located in / tests directory. Since its a time consuming process only simulated install is done on CI. Linux mint and Elementary are not tested in containers. It is possible that there might be some errors specific to your setup. Please report if so. It is Strongly advised to try simulate mode first before proceeding with actual installation. Warning Never set environment variable CI = true or TRAVIS = true , unless you are running in a CI environment or are sure of its effects.","title":"CI and Testing"},{"location":"yaml/","text":"YAML Config \u00b6 The configuration file is pretty much self explanatory so, I am going to just post a sample config file below. All Boolean fields are optional and if not provided or if found to be invalid, fallback to false. Default and sample configs can be found in config directory. # Install Config version : 5 name : Polaris author : Prasad T # Configurtaion config : # Enabled Tasks tasks : update : true upgrade : true # Add Repos # individual repos flags are mentioned under config . add_repo key repo : true # Add PPAs ppa : true # APT Packages apt : true # Whether to purge packages mentioned in config . purge key purge : true debs : true pip2 : true pip3 : true binaries : true # Repository Flags add_repo : winehq : true docker : true mendeley : false googlecloud : true spotify : true vscode : true skype : true signal : false insync : true google : true # Flags flags : # Simulate flag will never be overridden by remote config . purge_enabled : true preserve_debs : true # Packages to purge purge : - gnome - mines - gnome - sudoku - aisleriot - gnome - mahjongg # PPA List ppa : - ppa : dawidd0811 / neofetch - ppa : yubico / stable - ppa : teejee2008 / ppa # Install components # APT Packages , Python Modules , Debian packages install : # Python 2 Modules python2 : - docker - compose # Python 3 Modules python3 : - awscli # Debian packages : . deb files # CSV format similar to lists debian_packages : - https : // atom - installer . github . com / v1 . 28 . 0 / atom - amd64 . deb , Atom - Editor . deb - https : // download . teamviewer . com / download / teamviewer_i386 . deb , Teamviewer . deb # Static Binaries which will be placed in / usr / local / bin # minikube , docker - compose , etc . # Follows same pattern as Debian packages # Name to be saved is second field binaries : - https : // github . com / docker / compose / releases / download / 1 . 20 . 0 / docker - compose - linux - x86_64 , docker - compose - https : // github . com / kubernetes / minikube / releases / download / v0 . 28 . 2 / minikube - linux - amd64 , minikube - https : // github . com / kubernetes / kompose / releases / download / v1 . 19 . 0 / kompose - linux - amd64 , kompose apt : # Admin related Stuff administration : - dconf - editor - htop - apt - xapian - index - gdebi - gparted - synaptic - bleachbit # Security Related Stuff security : - gufw # Productivity & Office Tools . productivity : - empathy - evolution - realmd - pandoc - data - pandoc - texstudio - texlive - fonts - extra - texlive - formats - extra - texlive - fonts - recommended - texlive - science - texlive - generic - extra - texlive - xetex - texlive - luatex - texlive - pstricks - texlive - science - texlive - extra - utils - texlive - lang - english - texlive - lang - other - texlive - font - utils - texlive - publishers - gummi # Multimedia Tools . Photo Editors Converting tools , plex etc . multimedia : - audacity - vlc - gimp - handbrake - handbrake - cli - rawtherapee - darktable - mpv - pavucontrol - cheese # Tools related to development . development : - curl - spyder - spyder3 - git - shellcheck - ocl - icd - dev - opencl - headers - clinfo - vainfo - vdpauinfo - ocl - icd - libopencl1 - ruby - ruby - dev - python - magic - putty - python3 - pip - python - dateutil - python - pip - whl - python - pip # Everything Else # Which is conditional other : - gnome - online - miners # Packages supplied by external repositories & PPAs # Dont Mix packages provided by distribution and PPAs # Sometimes external repos and ppas fail , so better isolate it . external : - google - chrome - stable - spotify - client - code - google - cloud - sdk - docker - ce","title":"Example Config YAML"},{"location":"yaml/#yaml-config","text":"The configuration file is pretty much self explanatory so, I am going to just post a sample config file below. All Boolean fields are optional and if not provided or if found to be invalid, fallback to false. Default and sample configs can be found in config directory. # Install Config version : 5 name : Polaris author : Prasad T # Configurtaion config : # Enabled Tasks tasks : update : true upgrade : true # Add Repos # individual repos flags are mentioned under config . add_repo key repo : true # Add PPAs ppa : true # APT Packages apt : true # Whether to purge packages mentioned in config . purge key purge : true debs : true pip2 : true pip3 : true binaries : true # Repository Flags add_repo : winehq : true docker : true mendeley : false googlecloud : true spotify : true vscode : true skype : true signal : false insync : true google : true # Flags flags : # Simulate flag will never be overridden by remote config . purge_enabled : true preserve_debs : true # Packages to purge purge : - gnome - mines - gnome - sudoku - aisleriot - gnome - mahjongg # PPA List ppa : - ppa : dawidd0811 / neofetch - ppa : yubico / stable - ppa : teejee2008 / ppa # Install components # APT Packages , Python Modules , Debian packages install : # Python 2 Modules python2 : - docker - compose # Python 3 Modules python3 : - awscli # Debian packages : . deb files # CSV format similar to lists debian_packages : - https : // atom - installer . github . com / v1 . 28 . 0 / atom - amd64 . deb , Atom - Editor . deb - https : // download . teamviewer . com / download / teamviewer_i386 . deb , Teamviewer . deb # Static Binaries which will be placed in / usr / local / bin # minikube , docker - compose , etc . # Follows same pattern as Debian packages # Name to be saved is second field binaries : - https : // github . com / docker / compose / releases / download / 1 . 20 . 0 / docker - compose - linux - x86_64 , docker - compose - https : // github . com / kubernetes / minikube / releases / download / v0 . 28 . 2 / minikube - linux - amd64 , minikube - https : // github . com / kubernetes / kompose / releases / download / v1 . 19 . 0 / kompose - linux - amd64 , kompose apt : # Admin related Stuff administration : - dconf - editor - htop - apt - xapian - index - gdebi - gparted - synaptic - bleachbit # Security Related Stuff security : - gufw # Productivity & Office Tools . productivity : - empathy - evolution - realmd - pandoc - data - pandoc - texstudio - texlive - fonts - extra - texlive - formats - extra - texlive - fonts - recommended - texlive - science - texlive - generic - extra - texlive - xetex - texlive - luatex - texlive - pstricks - texlive - science - texlive - extra - utils - texlive - lang - english - texlive - lang - other - texlive - font - utils - texlive - publishers - gummi # Multimedia Tools . Photo Editors Converting tools , plex etc . multimedia : - audacity - vlc - gimp - handbrake - handbrake - cli - rawtherapee - darktable - mpv - pavucontrol - cheese # Tools related to development . development : - curl - spyder - spyder3 - git - shellcheck - ocl - icd - dev - opencl - headers - clinfo - vainfo - vdpauinfo - ocl - icd - libopencl1 - ruby - ruby - dev - python - magic - putty - python3 - pip - python - dateutil - python - pip - whl - python - pip # Everything Else # Which is conditional other : - gnome - online - miners # Packages supplied by external repositories & PPAs # Dont Mix packages provided by distribution and PPAs # Sometimes external repos and ppas fail , so better isolate it . external : - google - chrome - stable - spotify - client - code - google - cloud - sdk - docker - ce","title":"YAML Config"},{"location":"drafts/proposed-changes/","text":"Proposed Changes \u00b6 APT config for adding generic apt repos \u00b6 Not yet in stable. There is no plan to remove Google Chrome ROS VSCode Docker Spotify Skype Google Cloud from apt-repo configs. they will be supported with single entry config via add_repo . < id > . However following may be removed in the future versions as they are not supported properly by their vendors and often require some tweaks or for other reasons. You can add them via new apt_sources config if you want. InSync Duo Security GCSFUSE(hasen't been updated since bionic) apt_sources : # Comment, This will show in software properties - comment : Google Chrome # GPG key Can be URL or a GPG key # Keys will be retreived from ubuntu keyserver. key_url : key_id : # URL for repo # Variable interpolation is possible # Following variables are supported # CODE_NAME for release codename eg. bionic # DISTRO_NAME for name of the distribution eg.ubuntu source : # Additional architecture support armhf : true i386 : false arm64 : true # Supports Debian # Should be a bool # Default is true debian : true # Supports Derivatives like mint? # Can be yes, base or no # base will use ubuntu as its base # default is to use fix derivative : base # Some repositories only support LTS # Default is false ltsonly : false # Save .list file as # Mandatory # Do not inlude .list it will be added automatically name : google-chrome","title":"Proposed Changes"},{"location":"drafts/proposed-changes/#proposed-changes","text":"","title":"Proposed Changes"},{"location":"drafts/proposed-changes/#apt-config-for-adding-generic-apt-repos","text":"Not yet in stable. There is no plan to remove Google Chrome ROS VSCode Docker Spotify Skype Google Cloud from apt-repo configs. they will be supported with single entry config via add_repo . < id > . However following may be removed in the future versions as they are not supported properly by their vendors and often require some tweaks or for other reasons. You can add them via new apt_sources config if you want. InSync Duo Security GCSFUSE(hasen't been updated since bionic) apt_sources : # Comment, This will show in software properties - comment : Google Chrome # GPG key Can be URL or a GPG key # Keys will be retreived from ubuntu keyserver. key_url : key_id : # URL for repo # Variable interpolation is possible # Following variables are supported # CODE_NAME for release codename eg. bionic # DISTRO_NAME for name of the distribution eg.ubuntu source : # Additional architecture support armhf : true i386 : false arm64 : true # Supports Debian # Should be a bool # Default is true debian : true # Supports Derivatives like mint? # Can be yes, base or no # base will use ubuntu as its base # default is to use fix derivative : base # Some repositories only support LTS # Default is false ltsonly : false # Save .list file as # Mandatory # Do not inlude .list it will be added automatically name : google-chrome","title":"APT config for adding generic apt repos"},{"location":"faq/debug/","text":"Debugging the script \u00b6 You can chose from multiple debug modes. by setting DEBUG variable to one of the following DEBUG = 1 Print debug messages DEBUG = internal display some internal debug messages DEBUG = trace Print debug, internal and also apt logs. This can generate a lot of output. Local testing \u00b6 You can use . / tests / test - distro . sh to test the scripts locally. It uses docker to build and test the script in simulate mode inside containers. This script requires two arguments distro name and release node name . They are used as parameters to build the Docker image from dockerfile in dockerfiles / tests .eg.to test the script on Ubuntu 18.04 bionic, run it as . / tests / test - distro . sh ubuntu bionic . It will fetch and build the docker image and run the script in simulate mode using the config files at https : // { branch - name } --ubuntu-post-insta..netlify.net/config/default.yml Alternatively you can build the docker image yourself. and test it. $ export distro = \"ubuntu\" $ export release = \"bionic\" $ docker build -t ae: \" ${ distro } - ${ release } \" \\ --build-arg DISTRO = \" ${ distro } \" \\ --build-arg CODE_NAME = \" ${ release } \" \\ ./dockerfiles/tests $ docker run -it -v $( pwd ) /after-effects:/shared/after-effects:ro \\ -v $( pwd ) /config/:/shared/config:ro \\ ae:ubuntu-bionic root@a9f6bf377494:/shared# DEBUG = 1 ./after-effects -c config/default.yml -s -H [ Checking ] Permissions... [ DEBUG ] Initialize logging [ Success ] OK! running as root. [ DEBUG ] Architecture is 64 bit. [ Info ] Using custom config file [ Simulating ] is set to true [ Info ] YAML config will not be displayed. [ Info ] Checking dependencies... [ Notice ] Following details are recognised by the Script. [ Info ] Hostname: a9f6bf377494 [ Info ] UUID for Run: a8ce9e69-b967-4a59-841f-e317f0d18d25 [ Info ] Distro: ubuntu Tip This assumes that you can run docker without using sudo. Add yourself yo docker group or refer to docker documentation for more info. Documentation \u00b6 Docs are built using mkdocs. If you spot a mistake or a typo, you can submit a Pull request to fix it. You can test the docs locally with provided docker-compose file. docker-compose build docker-compose up and navigate to localhost:8000 to view the documentation.","title":"Debugging"},{"location":"faq/debug/#debugging-the-script","text":"You can chose from multiple debug modes. by setting DEBUG variable to one of the following DEBUG = 1 Print debug messages DEBUG = internal display some internal debug messages DEBUG = trace Print debug, internal and also apt logs. This can generate a lot of output.","title":"Debugging the script"},{"location":"faq/debug/#local-testing","text":"You can use . / tests / test - distro . sh to test the scripts locally. It uses docker to build and test the script in simulate mode inside containers. This script requires two arguments distro name and release node name . They are used as parameters to build the Docker image from dockerfile in dockerfiles / tests .eg.to test the script on Ubuntu 18.04 bionic, run it as . / tests / test - distro . sh ubuntu bionic . It will fetch and build the docker image and run the script in simulate mode using the config files at https : // { branch - name } --ubuntu-post-insta..netlify.net/config/default.yml Alternatively you can build the docker image yourself. and test it. $ export distro = \"ubuntu\" $ export release = \"bionic\" $ docker build -t ae: \" ${ distro } - ${ release } \" \\ --build-arg DISTRO = \" ${ distro } \" \\ --build-arg CODE_NAME = \" ${ release } \" \\ ./dockerfiles/tests $ docker run -it -v $( pwd ) /after-effects:/shared/after-effects:ro \\ -v $( pwd ) /config/:/shared/config:ro \\ ae:ubuntu-bionic root@a9f6bf377494:/shared# DEBUG = 1 ./after-effects -c config/default.yml -s -H [ Checking ] Permissions... [ DEBUG ] Initialize logging [ Success ] OK! running as root. [ DEBUG ] Architecture is 64 bit. [ Info ] Using custom config file [ Simulating ] is set to true [ Info ] YAML config will not be displayed. [ Info ] Checking dependencies... [ Notice ] Following details are recognised by the Script. [ Info ] Hostname: a9f6bf377494 [ Info ] UUID for Run: a8ce9e69-b967-4a59-841f-e317f0d18d25 [ Info ] Distro: ubuntu Tip This assumes that you can run docker without using sudo. Add yourself yo docker group or refer to docker documentation for more info.","title":"Local testing"},{"location":"faq/debug/#documentation","text":"Docs are built using mkdocs. If you spot a mistake or a typo, you can submit a Pull request to fix it. You can test the docs locally with provided docker-compose file. docker-compose build docker-compose up and navigate to localhost:8000 to view the documentation.","title":"Documentation"},{"location":"faq/dependencies/","text":"Dependencies \u00b6 What do I need to run this \u00b6 Usually nothing extra! Your base Ubuntu install comes with all the commands/utilities this script uses, unless you are running this on Ubuntu docker image. Core dependencies \u00b6 The script depends on following utilities which are usually present on a typical Ubuntu/Ubuntu based installation. If these packages are not installed, script will exit with error code 1. Install Dependencies sudo apt-get install -y --no-install-recommends lsb-release whiptail coreutils iputils-ping procps gpgv wget lsb - release , for determining the release and distribution. whiptail , to display the menu. coreutils cut, tr, grep etc. wget , to get deb packages, report stats, get version information. iputils - ping , to test connectivity. procps to check running processes gpg , gpgv to check signatures & add repositories awk , sed to parse configs bash (4.x) Note on Debian Debian releases, [especially in docker] images sometimes do not have ps binary from procps pre installed. Please install the dependency packages before running the script. Additional packages installed \u00b6 Some tasks might install packages automatically, which are required to perform certain actions. Additional APT packages installed Some apt packages will be installed automatically, as they are necessary to perform selected tasks. For repository related tasks \u00b6 apt-transport-https ca-certificates curl gnupg2 software-properties-common For installing python packages \u00b6 python-pip (for python 2) python3-pip (for python 3) For resetting repositories \u00b6 ppa-purge Additional dependencies of these packages will also be installed.","title":"Dependecies"},{"location":"faq/dependencies/#dependencies","text":"","title":"Dependencies"},{"location":"faq/dependencies/#what-do-i-need-to-run-this","text":"Usually nothing extra! Your base Ubuntu install comes with all the commands/utilities this script uses, unless you are running this on Ubuntu docker image.","title":"What do I need to run this"},{"location":"faq/dependencies/#core-dependencies","text":"The script depends on following utilities which are usually present on a typical Ubuntu/Ubuntu based installation. If these packages are not installed, script will exit with error code 1. Install Dependencies sudo apt-get install -y --no-install-recommends lsb-release whiptail coreutils iputils-ping procps gpgv wget lsb - release , for determining the release and distribution. whiptail , to display the menu. coreutils cut, tr, grep etc. wget , to get deb packages, report stats, get version information. iputils - ping , to test connectivity. procps to check running processes gpg , gpgv to check signatures & add repositories awk , sed to parse configs bash (4.x) Note on Debian Debian releases, [especially in docker] images sometimes do not have ps binary from procps pre installed. Please install the dependency packages before running the script.","title":"Core dependencies"},{"location":"faq/dependencies/#additional-packages-installed","text":"Some tasks might install packages automatically, which are required to perform certain actions. Additional APT packages installed Some apt packages will be installed automatically, as they are necessary to perform selected tasks.","title":"Additional packages installed"},{"location":"faq/dependencies/#for-repository-related-tasks","text":"apt-transport-https ca-certificates curl gnupg2 software-properties-common","title":"For repository related tasks"},{"location":"faq/dependencies/#for-installing-python-packages","text":"python-pip (for python 2) python3-pip (for python 3)","title":"For installing python packages"},{"location":"faq/dependencies/#for-resetting-repositories","text":"ppa-purge Additional dependencies of these packages will also be installed.","title":"For resetting repositories"},{"location":"faq/distros/","text":"Supported Distros \u00b6 In short? Ubuntu, its official flavors (Kubuntu,Ubuntu Mate etc), Linux Mint and Elementary. I have not tested the script on following distros, but since they use ubuntu as their base, It should work fine. But no promises. About 32 bit & ARM Support Though 32 bit & ARM is supported, Testing in Travis CI, containers and locally all are done using 64 bit machine and containers. If something breaks please report it and use it with caution on 32 bit machines. Some repositories are not available for ARM and 32 bit architecture. Since 17.10 Ubuntu no longer provides 32 bit ISO images. You have to use Ubuntu flavors like Lubuntu. Xubuntu or use minimal ISO. Warning! Script will exit, if it cannot recognize the distribution. A Complete list of supported distributions is given below. Distribution Code name/Version Supported Notes Ubuntu 19.10 Eoan Ermine Yes Ubuntu 19.04 Disco Dingo Yes Ubuntu 18.04 Bionic Beaver Yes Ubuntu 16.04 Xenial Xerus Yes Linux Mint 18 Sarah Yes Linux-Mint 18.1 Serena Yes Linux-Mint 18.2 Sonya Yes Linux-Mint 18.3 Sylvia Yes Linux Mint 19 Tara Yes Linux Mint 19.1 Tessa Yes Linux Mint 19.2 Tina Yes Debian 8 Jessie Yes Debian 9 Stretch Yes Debian 10 Buster --- Only use it for testing Elementary-OS 0.4 Loki Yes Not tested Elementary-OS 5.0 Juno Yes Not tested Budgie Remix 16.04 Yes PoP! OS Supported Ubuntu Yes Not tested Linux-Lite 3.X Yes (Based on Ubuntu 16.04) Bodhi Linux 4 Yes (Based on Ubuntu 16.04) KDE Neon Based on Ubuntu LTS Might be buggy Not Tested Peppermint 9,10 Based on Ubuntu 18.04 Yes Not Tested Peppermint 8 Based on Ubuntu 16.04 Yes Not tested Pre-Release and development builds Support for Ubuntu Pre-release builds, Elementary OS Juno are experimental and things might break. They have not been released in stable release channels and are considered development versions of the release. It is strongly advised to use them in a chroot or a in a VM and not as a daily driver. Debian Buster is in testing. Please use it with caution. New App-store on Linux Mint 18.3 and above Linux mint 18.3 & later releases uses a new App-Store, from which you can directly install Chrome and other popular tools. There may be some conflicts in the / etc / apt / sources . list . d . Where, a single repository might be configured multiple times with same priority. Use it with caution. The scripts are not tested on Travis on Linux Mint.","title":"Distros"},{"location":"faq/distros/#supported-distros","text":"In short? Ubuntu, its official flavors (Kubuntu,Ubuntu Mate etc), Linux Mint and Elementary. I have not tested the script on following distros, but since they use ubuntu as their base, It should work fine. But no promises. About 32 bit & ARM Support Though 32 bit & ARM is supported, Testing in Travis CI, containers and locally all are done using 64 bit machine and containers. If something breaks please report it and use it with caution on 32 bit machines. Some repositories are not available for ARM and 32 bit architecture. Since 17.10 Ubuntu no longer provides 32 bit ISO images. You have to use Ubuntu flavors like Lubuntu. Xubuntu or use minimal ISO. Warning! Script will exit, if it cannot recognize the distribution. A Complete list of supported distributions is given below. Distribution Code name/Version Supported Notes Ubuntu 19.10 Eoan Ermine Yes Ubuntu 19.04 Disco Dingo Yes Ubuntu 18.04 Bionic Beaver Yes Ubuntu 16.04 Xenial Xerus Yes Linux Mint 18 Sarah Yes Linux-Mint 18.1 Serena Yes Linux-Mint 18.2 Sonya Yes Linux-Mint 18.3 Sylvia Yes Linux Mint 19 Tara Yes Linux Mint 19.1 Tessa Yes Linux Mint 19.2 Tina Yes Debian 8 Jessie Yes Debian 9 Stretch Yes Debian 10 Buster --- Only use it for testing Elementary-OS 0.4 Loki Yes Not tested Elementary-OS 5.0 Juno Yes Not tested Budgie Remix 16.04 Yes PoP! OS Supported Ubuntu Yes Not tested Linux-Lite 3.X Yes (Based on Ubuntu 16.04) Bodhi Linux 4 Yes (Based on Ubuntu 16.04) KDE Neon Based on Ubuntu LTS Might be buggy Not Tested Peppermint 9,10 Based on Ubuntu 18.04 Yes Not Tested Peppermint 8 Based on Ubuntu 16.04 Yes Not tested Pre-Release and development builds Support for Ubuntu Pre-release builds, Elementary OS Juno are experimental and things might break. They have not been released in stable release channels and are considered development versions of the release. It is strongly advised to use them in a chroot or a in a VM and not as a daily driver. Debian Buster is in testing. Please use it with caution. New App-store on Linux Mint 18.3 and above Linux mint 18.3 & later releases uses a new App-Store, from which you can directly install Chrome and other popular tools. There may be some conflicts in the / etc / apt / sources . list . d . Where, a single repository might be configured multiple times with same priority. Use it with caution. The scripts are not tested on Travis on Linux Mint.","title":"Supported Distros"},{"location":"faq/errors/","text":"Errors \u00b6 GCSFUSE on 18.10+ \u00b6 Google 's GCSFuse is not yet available for cosmic/disco. Please see this Github issue for a fix. What if I get an error saying Unknown Distribution/Release? \u00b6 That usually means you are running a Distribution which is not supported or too old or a derivative which is not recognized by the script. However it also might be possible that lsb - release package is missing from your system. Since the script depends on it for determining what is the code-name of the release it will fail. You might see an error like this, ./after-effects: line 41: lsb_release: command not found ./after-effects: line 42: lsb_release: command not found ./after-effects: line 43: lsb_release: command not found ./after-effects: line 44: lsb_release: command not found [ Notice ] Following details were recognized by the Script. [ Info ] Distro: [ Info ] Version: [ Info ] Code Name: [ Info ] Architecture: amd64 [ Info ] Path for sources.list.d: /etc/apt/sources.list.d [ WARNING ] Will automatically assume yes for all the options available in the script! [ Simulating ] is set to true [ Derivatives ] Checking for Ubuntu based Distributions [ Error! ] Unknown Distribution/Release. [ Notice ] This Script is not designed to run on this () distro/release. It means that you do not have lsb-release package installed. It happens usually on docker containers. See What are its dependencies? What do I need on my system to run this? Install lsb - release package using apt - get - y install lsb - release In the case above you are probably missing other dependencies as well. It might be a good idea to install those dependencies first. What if I get an error saying this release of Ubuntu is no longer supported? \u00b6 [ EOL ] This release of Ubuntu is no longer supported. [ Notice ] zesty reached EOL on January 13th, 2018. [ Notice ] Please use a supported version of Ubuntu. [ Info ] Please visit the link below for information on how to upgrade. SSL Errors \u00b6 [ Error! ] Something went wrong while retrieving /tmp/api-version.yml. [ Error! ] Error Getting file. Try running wget https : // ae . prasadt . com / api / version . yml . If you see SSL errors, that means that your CA bundle is out of date. This project uses Amazon Root CA & LetsEncrypt for SSL, make sure that your system trusts these. Script throws a bunch of errors or got struck or hangs \u00b6 Report Well, that shouldn't have happened. Please consider opening an issue on Github . How to recover \u00b6 If you know where it was stuck/errored, just re-run the task(s) which were not completed. If you don't know, go and check log file. Each task is labeled and is clearly logged before starting and after completing. Just run the tasks which did not complete. You don't have to re-download the packages you have already downloaded, because they are already cached by apt-get. Remember, some operations of the script can be very lengthy and can involve lots of downloads (If you used default list files, expect up to 2 GB of traffic). So, it might appear that script is stuck because cursor stops blinking. However it is not the case. If you are unsure please check the logs. Tip In rare cases where your script exited while installing a DEB file, which has unmet dependencies, you might see broken packages error. In that case, run sudo apt - get install - f to fix the broken packages and run the script again. Issues not mentioned above? \u00b6 If you see any errors or script hangs/errors please do not hesitate to open an issue on Github .","title":"Errors & Issues"},{"location":"faq/errors/#errors","text":"","title":"Errors"},{"location":"faq/errors/#gcsfuse-on-1810","text":"Google 's GCSFuse is not yet available for cosmic/disco. Please see this Github issue for a fix.","title":"GCSFUSE on 18.10+"},{"location":"faq/errors/#what-if-i-get-an-error-saying-unknown-distributionrelease","text":"That usually means you are running a Distribution which is not supported or too old or a derivative which is not recognized by the script. However it also might be possible that lsb - release package is missing from your system. Since the script depends on it for determining what is the code-name of the release it will fail. You might see an error like this, ./after-effects: line 41: lsb_release: command not found ./after-effects: line 42: lsb_release: command not found ./after-effects: line 43: lsb_release: command not found ./after-effects: line 44: lsb_release: command not found [ Notice ] Following details were recognized by the Script. [ Info ] Distro: [ Info ] Version: [ Info ] Code Name: [ Info ] Architecture: amd64 [ Info ] Path for sources.list.d: /etc/apt/sources.list.d [ WARNING ] Will automatically assume yes for all the options available in the script! [ Simulating ] is set to true [ Derivatives ] Checking for Ubuntu based Distributions [ Error! ] Unknown Distribution/Release. [ Notice ] This Script is not designed to run on this () distro/release. It means that you do not have lsb-release package installed. It happens usually on docker containers. See What are its dependencies? What do I need on my system to run this? Install lsb - release package using apt - get - y install lsb - release In the case above you are probably missing other dependencies as well. It might be a good idea to install those dependencies first.","title":"What if I get an error saying Unknown Distribution/Release?"},{"location":"faq/errors/#what-if-i-get-an-error-saying-this-release-of-ubuntu-is-no-longer-supported","text":"[ EOL ] This release of Ubuntu is no longer supported. [ Notice ] zesty reached EOL on January 13th, 2018. [ Notice ] Please use a supported version of Ubuntu. [ Info ] Please visit the link below for information on how to upgrade.","title":"What if I get an error saying this release of Ubuntu is no longer supported?"},{"location":"faq/errors/#ssl-errors","text":"[ Error! ] Something went wrong while retrieving /tmp/api-version.yml. [ Error! ] Error Getting file. Try running wget https : // ae . prasadt . com / api / version . yml . If you see SSL errors, that means that your CA bundle is out of date. This project uses Amazon Root CA & LetsEncrypt for SSL, make sure that your system trusts these.","title":"SSL Errors"},{"location":"faq/errors/#script-throws-a-bunch-of-errors-or-got-struck-or-hangs","text":"Report Well, that shouldn't have happened. Please consider opening an issue on Github .","title":"Script throws a bunch of errors or got struck or hangs"},{"location":"faq/errors/#how-to-recover","text":"If you know where it was stuck/errored, just re-run the task(s) which were not completed. If you don't know, go and check log file. Each task is labeled and is clearly logged before starting and after completing. Just run the tasks which did not complete. You don't have to re-download the packages you have already downloaded, because they are already cached by apt-get. Remember, some operations of the script can be very lengthy and can involve lots of downloads (If you used default list files, expect up to 2 GB of traffic). So, it might appear that script is stuck because cursor stops blinking. However it is not the case. If you are unsure please check the logs. Tip In rare cases where your script exited while installing a DEB file, which has unmet dependencies, you might see broken packages error. In that case, run sudo apt - get install - f to fix the broken packages and run the script again.","title":"How to recover"},{"location":"faq/errors/#issues-not-mentioned-above","text":"If you see any errors or script hangs/errors please do not hesitate to open an issue on Github .","title":"Issues not mentioned above?"},{"location":"faq/exit-codes/","text":"Exit Codes \u00b6 Exit Codes Reason 1- 10 Script cannot run on the system 1 Dependencies are not met 2 Script not running as root 8 remote get operation failed. 10-19 Not Running with right configuration or internal flags 11 Unsupported Architecture 12 End of Life release 14 No Internet connection 15 Conflicting apps are running 16 Distribution is Not supported 17 Distribution is not yet supported. But will be in the future. 19 Internal Functions: Invalid arguments 20- 254 User configuration / Run-time errors 20 Purge function is called without -d flag 21 Failed to install dependencies 22 Invalid flag passed 23 Invalid argument position. 24 Not Running the latest version 25 Incompatible arguments 26 Option is obsolete 28 Getting API response failed 29 Stat reporting failed 35 Not a valid config file type 36 file defined does not exist/not accessible 37 Configuration error. Expects Boolean but found something else. 38 Failed to delete a file 39 Custom remote config name cannot be empty 40 Failed to unset an array 41 Failed to truncate clist file 51 GPG signature checks failed 52 SHA checksums did not match 61 apt-get update failed with some warnings or errors 255 Test Exit code","title":"Exit Codes"},{"location":"faq/exit-codes/#exit-codes","text":"Exit Codes Reason 1- 10 Script cannot run on the system 1 Dependencies are not met 2 Script not running as root 8 remote get operation failed. 10-19 Not Running with right configuration or internal flags 11 Unsupported Architecture 12 End of Life release 14 No Internet connection 15 Conflicting apps are running 16 Distribution is Not supported 17 Distribution is not yet supported. But will be in the future. 19 Internal Functions: Invalid arguments 20- 254 User configuration / Run-time errors 20 Purge function is called without -d flag 21 Failed to install dependencies 22 Invalid flag passed 23 Invalid argument position. 24 Not Running the latest version 25 Incompatible arguments 26 Option is obsolete 28 Getting API response failed 29 Stat reporting failed 35 Not a valid config file type 36 file defined does not exist/not accessible 37 Configuration error. Expects Boolean but found something else. 38 Failed to delete a file 39 Custom remote config name cannot be empty 40 Failed to unset an array 41 Failed to truncate clist file 51 GPG signature checks failed 52 SHA checksums did not match 61 apt-get update failed with some warnings or errors 255 Test Exit code","title":"Exit Codes"},{"location":"faq/linuxmint/","text":"Linux Mint 17.X and PPA priorities \u00b6 Note This applies only for Linux Mint 17, 17.1 and 17.2 For some reason, The Mint team decided to make their repository packages set with a priority of 700 in order to overwrite Ubuntu\u2019s priorities. PPAs typically issue a priority of 500, so due to the priority that Mint set, packages provided by the PPA which are already in the official mint repository (upstream Ubuntu as well) are completely ignored. Workaround is to set the priorities to lower for default repositories say 500 in /etc/apt/preferences.d/ or to increase priorities of PPAs to higher (more than 700). This was changed in Linux Mint 17.3 and no need to change the priorities unless it provides upstream Linux Mint packages. The release notes for mint 17.3 says Quote The \"upstream\" component of the Linux Mint repositories was kept at priority 700. All other components (\"main\", \"import\", \"backport\", \"romeo\") as well as the \"extra\" repository, had their priority lowered to 500.","title":"Linux Mint"},{"location":"faq/linuxmint/#linux-mint-17x-and-ppa-priorities","text":"Note This applies only for Linux Mint 17, 17.1 and 17.2 For some reason, The Mint team decided to make their repository packages set with a priority of 700 in order to overwrite Ubuntu\u2019s priorities. PPAs typically issue a priority of 500, so due to the priority that Mint set, packages provided by the PPA which are already in the official mint repository (upstream Ubuntu as well) are completely ignored. Workaround is to set the priorities to lower for default repositories say 500 in /etc/apt/preferences.d/ or to increase priorities of PPAs to higher (more than 700). This was changed in Linux Mint 17.3 and no need to change the priorities unless it provides upstream Linux Mint packages. The release notes for mint 17.3 says Quote The \"upstream\" component of the Linux Mint repositories was kept at priority 700. All other components (\"main\", \"import\", \"backport\", \"romeo\") as well as the \"extra\" repository, had their priority lowered to 500.","title":"Linux Mint 17.X and PPA priorities"},{"location":"faq/others/","text":"Others \u00b6 Support for Fedora/ Scientific Linux / Open SUSE / RHEL/ CentOS / put your favorite distro \u00b6 Its in the pipeline, but I cannot guarantee anything. Since I do not use anything other than Open SUSE very often, so it might take a while. But you can modify this script very easily to achieve that. You need to do the following things, Replace apt-get commands with their equivalents ( dnf or zypper or yum etc). Replace/Modify package names. Change add-repositories function to point to .repo files. Change dpkg to rpm equivalents. Since v5.0 Debian is supported. To-Do \u00b6 Gsettings Replace stupid bash parser with parser written in Go. Nod Modules & Ruby Gem installations. Option to upload log file to pastebin. Send a notification (Slack? Hipchat? Hangouts Chat?) after tasks are complete. Helpful if you are using ssh. Additional notes for sigma users \u00b6 Note This applies ONLY if you are using the script from sigma server. This does **NOT APPLY* for any GitHub branches/tags/releases.* DO NOT use Github version of get - after - effects . sh to get the script. Please follow the instructions in SETUP.MD [ Only preset on sigma server]. Several packages & some settings need to be manually configured to point to internal repositories & mirrors. Bootstrap function will automatically setup things for you. Groups & NFS mounts are also handled by bootstrap function. Currently Github branches do not report stats and report_stats is just a placeholder. If you are using the script from sigma server, stats are reported by default unless you disable them. UUID is NOT random for each run and is based on MAC address of one of your Ethernet devices.(If you have many) & hostname. Scripts have same version number and are always in sync with Github. You can identify the difference by looking at REL_NAME. Release name has - sigma appended to it. To see release number & name use . / after - effects - v . You do not have to run this as root . Security \u00b6 Well, this isn't very secure or meant to be. Verify the checksums on Github/Releases or Sigma Server. You can verify them manually or via . / after - effects --verify . Public Keys should be already in your keyring.","title":"Others"},{"location":"faq/others/#others","text":"","title":"Others"},{"location":"faq/others/#support-for-fedora-scientific-linux-open-suse-rhel-centos-put-your-favorite-distro","text":"Its in the pipeline, but I cannot guarantee anything. Since I do not use anything other than Open SUSE very often, so it might take a while. But you can modify this script very easily to achieve that. You need to do the following things, Replace apt-get commands with their equivalents ( dnf or zypper or yum etc). Replace/Modify package names. Change add-repositories function to point to .repo files. Change dpkg to rpm equivalents. Since v5.0 Debian is supported.","title":"Support for Fedora/ Scientific Linux / Open SUSE / RHEL/ CentOS / put your favorite distro"},{"location":"faq/others/#to-do","text":"Gsettings Replace stupid bash parser with parser written in Go. Nod Modules & Ruby Gem installations. Option to upload log file to pastebin. Send a notification (Slack? Hipchat? Hangouts Chat?) after tasks are complete. Helpful if you are using ssh.","title":"To-Do"},{"location":"faq/others/#additional-notes-for-sigma-users","text":"Note This applies ONLY if you are using the script from sigma server. This does **NOT APPLY* for any GitHub branches/tags/releases.* DO NOT use Github version of get - after - effects . sh to get the script. Please follow the instructions in SETUP.MD [ Only preset on sigma server]. Several packages & some settings need to be manually configured to point to internal repositories & mirrors. Bootstrap function will automatically setup things for you. Groups & NFS mounts are also handled by bootstrap function. Currently Github branches do not report stats and report_stats is just a placeholder. If you are using the script from sigma server, stats are reported by default unless you disable them. UUID is NOT random for each run and is based on MAC address of one of your Ethernet devices.(If you have many) & hostname. Scripts have same version number and are always in sync with Github. You can identify the difference by looking at REL_NAME. Release name has - sigma appended to it. To see release number & name use . / after - effects - v . You do not have to run this as root .","title":"Additional notes for sigma users"},{"location":"faq/others/#security","text":"Well, this isn't very secure or meant to be. Verify the checksums on Github/Releases or Sigma Server. You can verify them manually or via . / after - effects --verify . Public Keys should be already in your keyring.","title":"Security"}]}